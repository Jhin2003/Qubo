{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbc0298",
   "metadata": {},
   "source": [
    "Ingestion and Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "769dcd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1007 chunks to chunks.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Migs\\AppData\\Local\\Temp\\ipykernel_16956\\1226643297.py:59: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  created_at = datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "import pdfplumber\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "PDF_PATH = \"data_store/pdfs/prob.pdf\"\n",
    "OUT_PATH = \"chunks.jsonl\"\n",
    "\n",
    "# --- Helpers ---------------------------------------------------------------\n",
    "\n",
    "def sha1_of_file(path, buf_size=1024 * 1024):\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(buf_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def make_chunk_id(source_sha1: str, page: int, global_idx: int, page_idx: int) -> str:\n",
    "    # Deterministic, human-readable-ish ID\n",
    "    core = f\"{source_sha1[:12]}:p{page}:g{global_idx}:k{page_idx}\"\n",
    "    return hashlib.sha1(core.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# --- Extract per-page text -------------------------------------------------\n",
    "\n",
    "with pdfplumber.open(PDF_PATH) as pdf:\n",
    "    total_pages = len(pdf.pages)\n",
    "    page_texts = []\n",
    "    for i, page in enumerate(pdf.pages, start=1):\n",
    "        txt = page.extract_text() or \"\"\n",
    "        if txt.strip():\n",
    "            page_texts.append((i, txt))\n",
    "\n",
    "# --- Splitter (per page to keep page provenance) ---------------------------\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=1,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Build a global list of (page, chunk_text)\n",
    "chunks_with_pages = []\n",
    "for page_num, page_text in page_texts:\n",
    "    # Split this page's text; chunks won't cross pages\n",
    "    page_chunks = splitter.split_text(page_text)\n",
    "    for idx_in_page, ch in enumerate(page_chunks, start=1):\n",
    "        chunks_with_pages.append((page_num, idx_in_page, ch))\n",
    "\n",
    "# --- File-level provenance -------------------------------------------------\n",
    "\n",
    "source_name = os.path.basename(PDF_PATH)\n",
    "source_sha1 = sha1_of_file(PDF_PATH)\n",
    "created_at = datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
    "\n",
    "# --- Write JSONL with simplified structure -------------------------------\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for global_idx, (page_num, idx_in_page, chunk_text) in enumerate(chunks_with_pages):\n",
    "        meta = {\n",
    "            # Content (directly storing the text without extra nesting)\n",
    "            \"content\": chunk_text,\n",
    "            \n",
    "            # Metadata\n",
    "            \"metadata\": {\n",
    "                \"id\": make_chunk_id(source_sha1, page_num, global_idx, idx_in_page),\n",
    "                \"source\": source_name,\n",
    "                \"page\": page_num,\n",
    "                \"author\": \"Unknown\",  # You can add a way to extract the author if needed\n",
    "                \"created_at\": created_at,\n",
    "            },\n",
    "        }\n",
    "        f.write(json.dumps(meta, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {len(chunks_with_pages)} chunks to {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986facd",
   "metadata": {},
   "source": [
    "\n",
    "Embedding and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1154530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 documents.\n",
      "FAISS index saved to 'data_store/vector_databases.index' with 15 documents (metadata included).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Paths\n",
    "chunks_path = \"chunks.jsonl\"\n",
    "index_dir = \"data_store/vector_databases.index\"\n",
    "\n",
    "# --- Read chunks *with* metadata from JSONL ---\n",
    "def read_jsonl(file_path: str):\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            obj = json.loads(line)\n",
    "            text = obj[\"content\"]\n",
    "            metadata = obj.get(\"metadata\", {})\n",
    "            metadata.setdefault(\"chunk_number\", i)\n",
    "            texts.append(text)\n",
    "            metadatas.append(metadata)\n",
    "    return texts, metadatas\n",
    "\n",
    "\n",
    "\n",
    "# Load docs\n",
    "texts, metadatas = read_jsonl(chunks_path)\n",
    "print(f\"Loaded {len(texts)} documents.\")\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# --- Create FAISS vectorstore with normalization ---\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadatas,\n",
    "    normalize_L2=True   # <-- This ensures cosine similarity\n",
    ")\n",
    "\n",
    "# Save FAISS index + docstore\n",
    "Path(index_dir).mkdir(parents=True, exist_ok=True)\n",
    "vectorstore.save_local(index_dir)\n",
    "\n",
    "print(f\"FAISS index saved to '{index_dir}' with {len(texts)} documents (metadata included).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb494028",
   "metadata": {},
   "outputs": [],
   "source": [
    "Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5341fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Content: INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\n",
      "Review in Probability, Intro to RL Concepts\n",
      "Key idea:\n",
      "A simple event is when weâ€™re focusing on just one specific\n",
      "outcome.\n",
      "RJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs\n",
      "Metadata: {'id': 'f82e04e65af1c05c8deb7e1f09d0356d8bdda630', 'source': 'prob.pdf', 'page': 9, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 8}\n",
      "Score: -0.2948\n",
      "--------------------------------------------------\n",
      "[2]\n",
      "Content: INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\n",
      "Example\n",
      "In an experiment involving a sequence of 3 tosses of a coin, the number of\n",
      "getting heads H in the sequence is a random variable ð‘‹.\n",
      "Review in Probability, Intro to RL Concepts\n",
      "ð‘ƒ(ð‘‹ = 0) = 1/8 (T, T, T)\n",
      "ð‘ƒ(ð‘‹ = 1) = 3/8 (H, T, T), (T, H, T), (T, T, H)\n",
      "ð‘ƒ(ð‘‹ = 2) = 3/8 (H, H, T), (H, T, H), (T, H, H)\n",
      "ð‘ƒ(ð‘‹ = 3) = 1/8 (H, H, H)\n",
      "ð‘ƒ(ð‘‹ â‰¥ 4) = 0\n",
      "RJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs\n",
      "Metadata: {'id': 'fa431318d995e71224d01cbd3d1e7045ba8a1ab7', 'source': 'prob.pdf', 'page': 7, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 6}\n",
      "Score: -0.3099\n",
      "--------------------------------------------------\n",
      "[3]\n",
      "Content: INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\n",
      "Example\n",
      "â€¢ The most fundamental stochastic experiment is the experiment where a coin\n",
      "is tossed a number of times, say ð‘› times.\n",
      "Review in Probability, Intro to RL Concepts\n",
      "â€¢ Tossing a coin a few times wonâ€™t immediately give you a 50% chance for all\n",
      "outcomes. But tossing it many, many times will.\n",
      "the Law of Large Numbers. It tells us that\n",
      "over a large number of trials, the results will\n",
      "settle into predictable patterns.\n",
      "RJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs\n",
      "Metadata: {'id': '6163987db17fd5e83e42f8a3ca8ce3414d5ae349', 'source': 'prob.pdf', 'page': 4, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 3}\n",
      "Score: -0.3126\n",
      "--------------------------------------------------\n",
      "[4]\n",
      "Content: INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\n",
      "Random Variables\n",
      "â€¢ A particular number which is associated with or depends on the outcomes of\n",
      "a random event.\n",
      "Review in Probability, Intro to RL Concepts\n",
      "â€¢ Mathematically, a random variable is a real-valued function of the\n",
      "experimental outcome.\n",
      "â€¢ Denoted as ð‘‹. Thus, we write ð‘ƒ(ð‘‹ = ð‘¥).\n",
      "RJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs\n",
      "Metadata: {'id': '36768dad4cb166c508eacc733cf1b59501ee8431', 'source': 'prob.pdf', 'page': 5, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 4}\n",
      "Score: -0.3243\n",
      "--------------------------------------------------\n",
      "[5]\n",
      "Content: INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\n",
      "Probability Mass Function (PMF)\n",
      "Review in Probability, Intro to RL Concepts\n",
      "1/8 for 0 heads\n",
      "3/8 for 1 head\n",
      "3/8 for 2 heads\n",
      "1/8 for 3 heads\n",
      "Add them up:\n",
      "1/8+3/8+3/8+1/8=1\n",
      "VALID\n",
      "If you're tossing a coin 3 times, you canâ€™t get 5 heads. So P(X = 5) would\n",
      "be 0\n",
      "RJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs\n",
      "Metadata: {'id': '2e340dec1cc9e6f94e966fae357fa807601d2cd7', 'source': 'prob.pdf', 'page': 12, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 11}\n",
      "Score: -0.3484\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Migs\\AppData\\Local\\Temp\\ipykernel_16956\\1602824870.py:6: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='4bdc8745-99ef-4bbb-925f-f7fcce200673', metadata={'id': 'f82e04e65af1c05c8deb7e1f09d0356d8bdda630', 'source': 'prob.pdf', 'page': 9, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 8}, page_content='INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\\nReview in Probability, Intro to RL Concepts\\nKey idea:\\nA simple event is when weâ€™re focusing on just one specific\\noutcome.\\nRJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs'), np.float32(-0.29478204)), (Document(id='e6112540-baa6-436d-be9d-1dd9ccfa1271', metadata={'id': 'fa431318d995e71224d01cbd3d1e7045ba8a1ab7', 'source': 'prob.pdf', 'page': 7, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 6}, page_content='INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\\nExample\\nIn an experiment involving a sequence of 3 tosses of a coin, the number of\\ngetting heads H in the sequence is a random variable ð‘‹.\\nReview in Probability, Intro to RL Concepts\\nð‘ƒ(ð‘‹ = 0) = 1/8 (T, T, T)\\nð‘ƒ(ð‘‹ = 1) = 3/8 (H, T, T), (T, H, T), (T, T, H)\\nð‘ƒ(ð‘‹ = 2) = 3/8 (H, H, T), (H, T, H), (T, H, H)\\nð‘ƒ(ð‘‹ = 3) = 1/8 (H, H, H)\\nð‘ƒ(ð‘‹ â‰¥ 4) = 0\\nRJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs'), np.float32(-0.3098501)), (Document(id='63b278e9-1243-4e08-b051-f28f3fe5cf07', metadata={'id': '6163987db17fd5e83e42f8a3ca8ce3414d5ae349', 'source': 'prob.pdf', 'page': 4, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 3}, page_content='INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\\nExample\\nâ€¢ The most fundamental stochastic experiment is the experiment where a coin\\nis tossed a number of times, say ð‘› times.\\nReview in Probability, Intro to RL Concepts\\nâ€¢ Tossing a coin a few times wonâ€™t immediately give you a 50% chance for all\\noutcomes. But tossing it many, many times will.\\nthe Law of Large Numbers. It tells us that\\nover a large number of trials, the results will\\nsettle into predictable patterns.\\nRJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs'), np.float32(-0.31262767)), (Document(id='4b908f2b-c788-4b93-9264-d43d1a58d9b8', metadata={'id': '36768dad4cb166c508eacc733cf1b59501ee8431', 'source': 'prob.pdf', 'page': 5, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 4}, page_content='INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\\nRandom Variables\\nâ€¢ A particular number which is associated with or depends on the outcomes of\\na random event.\\nReview in Probability, Intro to RL Concepts\\nâ€¢ Mathematically, a random variable is a real-valued function of the\\nexperimental outcome.\\nâ€¢ Denoted as ð‘‹. Thus, we write ð‘ƒ(ð‘‹ = ð‘¥).\\nRJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs'), np.float32(-0.32426333)), (Document(id='f70880a2-0798-41d8-9f03-a5f81e6a30ad', metadata={'id': '2e340dec1cc9e6f94e966fae357fa807601d2cd7', 'source': 'prob.pdf', 'page': 12, 'author': 'Unknown', 'created_at': '2025-08-26T11:29:15Z', 'chunk_number': 11}, page_content=\"INTRODUCTION TO COMPUTING Course Code: CCINCOM/L\\nProbability Mass Function (PMF)\\nReview in Probability, Intro to RL Concepts\\n1/8 for 0 heads\\n3/8 for 1 head\\n3/8 for 2 heads\\n1/8 for 3 heads\\nAdd them up:\\n1/8+3/8+3/8+1/8=1\\nVALID\\nIf you're tossing a coin 3 times, you canâ€™t get 5 heads. So P(X = 5) would\\nbe 0\\nRJoEsINeFpOh RMCaErMviEnN RT. ILmEpAeRrNiaINl G NU College of Computing and InCfoourrmsaet Cioond Tee: cChCnRoNloFgLiReLs\"), np.float32(-0.34837532))]\n",
      "  results = vectorstore.similarity_search_with_relevance_scores(query, k=5)\n"
     ]
    }
   ],
   "source": [
    "# Load the FAISS index from disk\n",
    "vectorstore = FAISS.load_local(\"data_store/vector_databases.index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Query the index\n",
    "query = \"Hello\"\n",
    "results = vectorstore.similarity_search_with_relevance_scores(query, k=5)\n",
    "\n",
    "# Print results\n",
    "for i, (doc, score) in enumerate(results, start=1):\n",
    "    print(f\"[{i}]\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d8da3",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b47dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The probability is a measurement of uncertainty that tells us how likely it is that a particular event will occur. It can be denoted as P(A) where A is an event or a collection of possible outcomes. In the context of discrete probability, the probability of an event A occurring is calculated as the ratio of the number of elements in A to the total possible outcomes:\n",
      "\n",
      "P(A) = (Number of elements in A) / (Total possible outcomes)\n",
      "\n",
      "For example, if there's only one 4, and six possible numbers in total, we say the probability of getting a 4 is 1 out of 6, or:\n",
      "\n",
      "P(4) = 1/6\n",
      "\n",
      "This matches the formula shown on the slide. In this case, A represents the event \"getting a 4\".\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "# Initialize your retriever from FAISS\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Initialize your Ollama LLM\n",
    "llm = Ollama(model=\"mistral:instruct\")\n",
    "\n",
    "\n",
    "with open(\"prompt_template/qa.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_text = f.read()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_text\n",
    ")\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True,        # <<â€” important\n",
    ")\n",
    "\n",
    "query = \"what is probability\"\n",
    "\n",
    "res = qa_chain.invoke({\"query\": query})  # prefer .invoke to get the dict\n",
    "print(res[\"result\"])\n",
    "\n",
    "# Pretty-print unique sources\n",
    "seen = set()\n",
    "print(\"\\nSources:\")\n",
    "for doc in res[\"source_documents\"]:\n",
    "    src = doc.metadata.get(\"source\") or doc.metadata.get(\"file_path\") or \"unknown\"\n",
    "    page = doc.metadata.get(\"page\")\n",
    "    key = (src, page)\n",
    "    if key in seen: \n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # nice short name\n",
    "    short = Path(src).name if isinstance(src, str) else str(src)\n",
    "    if page is not None:\n",
    "        print(f\"- {short} (page {page})\")\n",
    "    else:\n",
    "        print(f\"- {short}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
