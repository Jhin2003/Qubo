{"content": "A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current\nLandscapeandFutureDirections\nShailjaGupta(CarnegieMellonUniversity,USA)\nRajeshRanjan(CarnegieMellonUniversity,USA)\nSuryaNarayanSingh(BITSindri,India)\nAbstract\nThis paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its\nevolution from foundational concepts to the current state of theart.RAGcombinesretrievalmechanisms\nwith generative language modelstoenhancetheaccuracyofoutputs,addressingkeylimitationsofLLMs.", "metadata": {"id": "905dd6887b2400a2bcf1d7c37b0f7be021abfce2", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 1, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "with generative language modelstoenhancetheaccuracyofoutputs,addressingkeylimitationsofLLMs.\nThestudyexploresthebasicarchitectureofRAG,focusingonhowretrievalandgenerationareintegrated\nto handle knowledge-intensive tasks. A detailed review of the significant technological advancements in\nRAG is provided, including key innovations in retrieval-augmented language models and applications\nacross various domains such as question-answering, summarization, and knowledge-based tasks.\nRecent research breakthroughs are discussed, highlighting novel methods for improving retrieval", "metadata": {"id": "0796974766980065721045bfa4cdb02cd701ed44", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 1, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Recent research breakthroughs are discussed, highlighting novel methods for improving retrieval\nefficiency. Furthermore, the paper examines ongoing challenges such as scalability, bias, and ethical\nconcerns in deployment. Future research directions are proposed, with a focus on improving the\nrobustness of RAG models, expanding the scope of application of RAGmodels,andaddressingsocietal\nimplications. This survey aims to serve as a foundational resource for researchers and practitioners in\nunderstandingthepotentialofRAGanditstrajectoryinthefieldofnaturallanguageprocessing.", "metadata": {"id": "32e17383927f5359aad86b7ad70ec826ad0b0e90", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 1, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "understandingthepotentialofRAGanditstrajectoryinthefieldofnaturallanguageprocessing.\nFigure1:TrendsinRAGcapturedfromrecentresearchpapers\nKeywords: Retrieval-Augmented Generation (RAG),InformationRetrieval,NaturalLanguageProcessing\n(NLP),ArtificialIntelligence(AI),MachineLearning(ML),LargeLanguageModel(LLM).", "metadata": {"id": "43e52d766c4600b3569ef23249fb54c6334c008e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 1, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Introduction\n1.1IntroductionofNaturalLanguageGeneration(NLG)\nNatural Language Processing (NLP) has become a pivotal domain within artificial intelligence (AI), with\napplications ranging from simple text classification to more complex tasks such as summarization,\nmachinetranslation,andquestionanswering.AparticularlysignificantbranchofNLPisNaturalLanguage\nGeneration (NLG), which focuses on the production of human-like language from structured or\nunstructured data. NLG's goal is to enable machines to generate coherent, relevant, and context-aware", "metadata": {"id": "336d64d8c95b8ae53bc767e42cddd3bedda5ef9c", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "text,improvinginteractionsbetweenhumansandmachines(Gattet.al.2018).AsAIevolves,thedemand\nfor more contextually awareandfactuallygroundedgeneratedcontenthasincreased,bringingaboutnew\nchallengesandinnovationsinNLG.\nTraditional NLG models, especially sequence-to-sequence architectures (Sutskever et al. 2014), have\nexhibited significant advancements ingeneratingfluentandcoherenttext.However,thesemodelstendto\nrely heavily on training data, often struggling when tasked with generating factually accurate or", "metadata": {"id": "c2d3ed9ba919c911b0ec079195a54431de2854e7", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "rely heavily on training data, often struggling when tasked with generating factually accurate or\ncontextually rich content for queries that require knowledge beyond theirtrainingset.Asaresult,models\nlike GPT (Radford et al. 2019) or BERT-based (Devlin et al. 2019) text generators are prone to\nhallucinations, where they produceplausiblebutincorrectornon-existentinformation(Jietal.2022).This\nlimitation has prompted the exploration of hybrid models that combine retrieval mechanisms with\ngenerative capabilities to ensure both fluency and factual correctness in outputs. There has been a", "metadata": {"id": "c6cd5c797dcc2ebc1e2f520907e98d38c9334e07", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "generative capabilities to ensure both fluency and factual correctness in outputs. There has been a\nsignificant rise in several research papers in this field and several new methods across the RAG\ncomponents have been proposed. Apart from new algorithms and methods, RAG has also seen steep\nadoption across various applications. However, there is a gapinasufficientsurveyofthisspacetracking\ntheevolutionandrecentchangesinthisspace.Thecurrentsurveyintendstofillthisgap.\n1.2OverviewofRetrieval-AugmentedGeneration(RAG)", "metadata": {"id": "98ea8b86718bcfaf2fd114db039092ff44a473d9", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "1.2OverviewofRetrieval-AugmentedGeneration(RAG)\nRetrieval-Augmented Generation (RAG) is an emerging hybrid architecture designed to address the\nlimitations of pure generative models. RAG integrates two key components: (i) a retrieval mechanism,\nwhich retrieves relevant documents or information from an external knowledge source, and (ii) a\ngeneration module, which processesthisinformationtogeneratehuman-liketext(Lewisetal.2020).This\ncombination allows RAG models to not only generate fluent text but also ground their outputs in\nreal-world,up-to-datedata.", "metadata": {"id": "52f1889f310ada7fc97f5046c6eee5179c350809", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "real-world,up-to-datedata.\nThe retrieval module in RAG typically leverages dense vector representations to identify relevant\ndocuments from large datasets, such as Wikipedia or proprietary databases. Once retrieved, these\ndocuments are passed to the generative module, often built using transformer-based architectures, to\ngenerate responses grounded in the retrieved knowledge. This methodology helps mitigate the\nhallucination problem and ensures that the generated text is more factual and contextually appropriate", "metadata": {"id": "1e8d6a0b1e95bf2a166fe8f1e386ff9bf2e1ff0b", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "(Thakur et al. 2021). Over the period, RAG models have seen applicationsinvariousdomains,including\nopen-domain question answering (Karpukhin et al., 2020), conversational agents (Liu et al. 2021), and\npersonalizedrecommendations.", "metadata": {"id": "8992cccf163deeb01c91b5d30c9881077222d51a", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 2, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Figure2:AbasicflowoftheRAGsystemalongwithitscomponent\n1.3EvolutionofHybridModelsinNLP\nBefore the introduction of RAG, NLP modelsprimarilyreliedoneitherretrievalorgenerationapproaches,\neach with its own set of advantages and limitations. Retrieval-based systems, such as traditional\ninformation retrieval engines (Salton et al., 1975), efficiently provided relevant documents or snippets in\nresponse to a query but could not synthesize new information or present the results in a coherent\nnarrative. On the other hand, purely generative models, which became popular with the rise of", "metadata": {"id": "724fd0c16362d90624df70bb6a0edc95227dbdeb", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 3, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "narrative. On the other hand, purely generative models, which became popular with the rise of\ntransformer architectures (Vaswani et al. 2017), offered fluency and creativity but often lacked factual\naccuracy.\nThe development of hybrid systems combining retrieval and generation began to gain momentum as\nresearchers recognizedthecomplementarystrengthsofbothapproaches.Earlyeffortsinhybridmodeling\ncan be traced back to works like DrQA (Chen et al. 2017), which employed retrieval techniques to fetch\nrelevant documents for question-answering tasks. However, the generative component in such systems", "metadata": {"id": "47d19d2125ee7598765555002df98886796c5758", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 3, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "relevant documents for question-answering tasks. However, the generative component in such systems\nwas minimal, often limited to selecting text directlyfromtheretrieveddocuments.Similarly,inmodelslike\nInformationRetrieval(Daietal.2019),retrievalwastreatedasdistinct,independentcomponents.\nThe real innovation came with the realization that retrieval and generation could be tightly integrated.\nModels like REALM (Guu et al., 2020) represented a key milestone, as they trained the retrieval and\ngenerative components jointly, enabling better alignment between the retrieved information and the", "metadata": {"id": "ef89f383b8a6d30b1b8411b1f12af0d4622d38e5", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 3, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "generative components jointly, enabling better alignment between the retrieved information and the\ngenerated output. RAG (Lewis et al. 2020) further extended this paradigm by using dense passage\nretrieval (Karpukhin et al., 2020) to fetch relevant documents and transformers like BART (Lewis et al.,\n2020) for a generation. This architecture provided a more seamless integration of retrieval and\ngeneration,allowingthemodeltoansweropen-endedquestionswithbothfluencyandfactualgrounding.\n1.4ImportanceofFactuallyGroundedLanguageGeneration", "metadata": {"id": "97531142604522e9743054670f0afe82e13e4d87", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 3, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "1.4ImportanceofFactuallyGroundedLanguageGeneration\nOne of the main motivations for developing RAG is the increasing demand for factually accurate,\ncontextually relevant, and up-to-date generated content. Inmanyapplications,suchascustomerservice,\nmedical diagnostics, or legal advisory systems, the need for reliable and grounded responses is\nparamount. Generative models that produce hallucinated or inaccurate information can lead to serious\nconsequences,suchasspreadingmisinformationorprovidingincorrectadvice(Jietal.2022).", "metadata": {"id": "da30c6a7d01872269918c5862f630d5a583798ee", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 3, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "RAG models directly address these concerns by grounding their generative process in external,\nup-to-date knowledge sources. This groundingimprovesthefactualaccuracyoftheoutputandenhances\nthe relevance of responses by incorporating real-world data that is directly tiedtothequery.Additionally,\nRAG models are less likely to propagate biases present in static training data,astheycanretrievemore\ndiverseandbalancedinformationfromexternalsources\n1.5ApplicationsofRAGModels\nRAG models have been applied across a wide array of domains where factual accuracy and contextual", "metadata": {"id": "d860187c5d2be727553ca62dd0e9997dc638a4b5", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "RAG models have been applied across a wide array of domains where factual accuracy and contextual\nunderstanding are critical. One ofthemostprominentapplicationsisinopen-domainquestionanswering,\nwhere the model must generate answers based on a wide range of topics. RAG has proven effective in\nimproving answer accuracy byretrievingrelevantinformationandthengeneratingresponsesgroundedin\nthat data (Izacard et. al. 2021). Models like Dense PassageRetrieval(DPR)(Karpukhinetal.,2020)and\nFusion-in-Decoder(Izacardet.al.2021)havebeenusedtogreateffectinthiscontext,showingsignificant", "metadata": {"id": "9a11e2495a6b1cb0c1803d112316366f7c968908", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Fusion-in-Decoder(Izacardet.al.2021)havebeenusedtogreateffectinthiscontext,showingsignificant\nimprovementsovertraditionalgenerativeorretrieval-onlymodels.\nIn conversational AI, RAG models have enhanced the capabilities of dialogue systems by ensuring that\nresponses are both coherent and grounded in factual information (Roller et al., 2020). For example,\nchatbots used in customer service can benefit from RAG's ability to retrievespecificdetailsfromproduct\ndatabasesordocumentation,leadingtomoreaccurateandusefulresponsesforend-users.", "metadata": {"id": "1e4ce8e9ad0552a99df2ca0ab8c9878609c04d8b", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "databasesordocumentation,leadingtomoreaccurateandusefulresponsesforend-users.\nOther applications include medical diagnosis systems, where RAG can retrieve and integrate the latest\nresearch findings or patient-specific data togenerateaccuratediagnosticsuggestions,andlegaladvisory\nsystems, where the model can retrieve relevant case law or statutes to provide legally sound advice.\nFurthermore, RAGhasfoundapplicationsinpersonalizedrecommendationsystems,whereitcanretrieve\nuserpreferencesorpastinteractionsandgeneratepersonalizedsuggestions.\n1.6ChallengesandLimitationsofRAG", "metadata": {"id": "a40b868ccc5375aa2ce36a5d0f25acd27f7f5635", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "1.6ChallengesandLimitationsofRAG\nDespite the promise of RAG models, several challenges need attention. The retrieval mechanism, while\npowerful, can still struggle with retrieving the most relevant documents, particularly when dealing with\nambiguous queries or niche knowledge domains. The reliance on dense vectorrepresentations,suchas\nthose used in DPR, can sometimes lead to irrelevant or off-topic documents being retrieved. Efforts to\nrefine retrieval techniques, including the incorporation of more sophisticated query expansion and", "metadata": {"id": "60f7c09c68acd5e748732d8a3a4a2408b82a043f", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "refine retrieval techniques, including the incorporation of more sophisticated query expansion and\ncontextual disambiguation, are needed to improve performance in these areas. The integration between\nretrieval and generation, while seamless in theory, can sometimes fail in practice. For instance, the\ngenerative module may not always effectively incorporate the retrieved information into its responses,\nleading to inconsistencies or incoherence between the retrieved facts and the generated text. Research", "metadata": {"id": "92dad325404ec1fe6bb9fe5d637513e77619fa42", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "into better alignment mechanisms, such as improved attention models or hierarchical fusion techniques,\nmay help alleviate these issues (Izacard et. al. 2021). Additionally, the computational overhead of RAG\nmodels is a concern, as they require both a retrieval and a generation step for each query. This dual\nprocess can be resource-intensive, particularly for large-scale applications (Borgeaud et al. 2021).\nTechniques such as model pruning (Han et al. 2015) or knowledge distillation (Sanh et al., 2019) may", "metadata": {"id": "1b1f1722628cd369406f8b27f9b59900ddfd3af4", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "offer ways to reduce the computational burden without sacrificing performance. Finally, there are ethical\nconcerns associated with the deployment of RAG models, particularly in termsofbiasandtransparency.\nBiases in AI and LLM have been a well-researched and evolving field with researchers identifying\ndifferent types of biases not limited to Gender, socio-economic class, or even educational background\n(Gupta et. al. 2024; Ranjan et. al., 2024). While RAG has the potential to reduce biases by retrieving", "metadata": {"id": "d955e630bf036cc5680d68162912b2454af9754f", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "more balanced information, there is still the risk of amplifying biases present in the retrieved sources", "metadata": {"id": "3c1c0b2572eb939b67584899da4d0714f2403d0e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 4, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "(Binns, 2018). Furthermore, ensuring transparency in how retrieval results are selected and used in\ngenerationiscrucialformaintainingtrustinthesesystems.\n1.7ScopeoftheSurvey\nThis paper aims to provide a comprehensive survey of RAG models, covering their evolution, key\narchitectural components, recent research in this area, current challenges and limitations of RAG, and\nfutureresearchdirection.\n2:CoreComponentsandArchitecturalOverviewofRAGSystems\n2.1OverviewofRAGModels\nRetrieval-augmented generation (RAG) is an advanced hybrid model architecture that augments natural", "metadata": {"id": "4e97569080a66a3cc3c7dd9b88212fb0278127b6", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 5, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Retrieval-augmented generation (RAG) is an advanced hybrid model architecture that augments natural\nlanguage generation (NLG) with external retrieval mechanisms to enhance themodel'sknowledgebase.\nTraditional large language models (LLMs) such as GPT-3 and BERT, which are pre-trained on vast\ncorpora, rely entirely on their internal representations of knowledge, making them susceptible to issues\nlike hallucinations—where the models generate plausible butincorrectinformation.Thesemodelscannot\nefficiently update their knowledge bases without retraining, making them less practical for dynamic,", "metadata": {"id": "65aaa81b85cb543bc302a8ec353e546e49391ab0", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 5, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "knowledge-intensive tasks like open-domain question answering and fact verification (Brown, T., et al.\n2020). Toovercometheselimitations,thepaper(Lewisetal.2020)proposedtheRAGarchitecture,which\nretrievesreal-time,relevantexternaldocumentstogroundthegeneratedtextinfactualinformation.\nTheRAGmodelincorporatestwokeycomponents:\n1. Retriever: This retrieves the most relevant documents from a corpus using techniques such as\ndensepassageretrieval(DPR)(Karpukhinet.al.2020)ortraditionalBM25algorithms.\n2. Generator: It synthesizes the retrieved documents into coherent, contextually relevant\nresponses.", "metadata": {"id": "db09170093234542cf2a700c282d901921cba590", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 5, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "responses.\nRAG’s strength lies in its ability to leverage external knowledge dynamically, allowing it to outperform\ngenerative models like GPT-3andknowledge-groundedsystemslikeBERT,whichrelyonstaticdatasets.\nIn open-domain question answering, RAG has been demonstrated to be highly effective, consistently\nretrievingrelevantinformationandimprovingthefactualaccuracyofthegeneratedresponses(Guu,K.,et\nal. 2020). In addition to knowledge retrieval, RAG models excel at updating knowledgebases.Sincethe\nmodel fetches external documents for each query, it requires no retraining to incorporate the latest", "metadata": {"id": "9cce0f35e5472034444e444577158781daa26a04", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 5, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "information. This flexibility makes RAG models particularly suitable for domains where information is\nconstantly evolving, such as medical research, financial news, and legal proceedings. Furthermore,\nstudies have shown that RAG models achieve superior results in a varietyofknowledge-intensivetasks,\nincludingdocumentsummarizationand,knowledge-groundeddialogues\n2.2RetrieverMechanismsinRAGSystems\nThe retriever in RAG systems is essential for fetching relevant documents from an external corpus.", "metadata": {"id": "475abcf984ab96eeddd7ee4fd733566f141a1bac", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 5, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "The retriever in RAG systems is essential for fetching relevant documents from an external corpus.\nEffective retrieval ensures that the model's output is grounded in accurate information. Several retrieval\nmechanisms are commonly used, ranging from traditional methods like BM25 to more sophisticated\ntechniqueslikeDensePassageRetrieval(DPR).", "metadata": {"id": "106fb2cb66bb8d7f65f303d23694c8cfd9d21605", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 5, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "2.2.1BM25\nBM25 is a well-established informationretrievalalgorithmthatusesthetermfrequency-inversedocument\nfrequency (TF-IDF) to rank documents according to relevance. Despite being a classical method, BM25\nremains a strong baseline for many modern retrieval systems, including those used in RAG models.\nBM25 calculates therelevancescoreofadocumentbasedonhowfrequentlyaquerytermappearsinthe\ndocument while adjusting for the document's length and the frequency of the term across the corpus\n(Robertson et. al. 2009).WhileBM25iseffectiveforkeywordmatching,ithaslimitationsinunderstanding", "metadata": {"id": "79e601c86dc7e55df1b4f1ad6e0d762a8baea0af", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "(Robertson et. al. 2009).WhileBM25iseffectiveforkeywordmatching,ithaslimitationsinunderstanding\nsemantic meaning. For example, BM25 cannot capture the relationships between words and tends to\nperform poorly on more complex, natural language queries that require an understanding of context.\nDespite this limitation, BM25 is still widely used because ofitssimplicityandefficiency.BM25iseffective\nfor tasks involvingsimpler,keyword-basedqueries,althoughmoremodernretrievalmodelslikeDPRtend\ntooutperformitinsemanticallycomplextasks.\n2.2.2DensePassageRetrieval(DPR)", "metadata": {"id": "fdf5f579f8b85ac662ee0013804569f2a6d6598a", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "tooutperformitinsemanticallycomplextasks.\n2.2.2DensePassageRetrieval(DPR)\nDense Passage Retrieval (DPR), introduced by Karpukhin et al. (2020), represents a more modern\napproach to information retrieval. It uses a dense vector space in which both the query and the\ndocuments are encoded into high-dimensional vectors. DPR employs a bi-encoder architecture, where\nthe query and documents are encoded separately, allowing for efficient nearest-neighbor search (Xiong\net. al. 2020). Unlike BM25, DPR excels at capturing semantic similarity between the query and", "metadata": {"id": "0097d485dd3a45ccd4d2d3529b13493f17d5d5a0", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "et. al. 2020). Unlike BM25, DPR excels at capturing semantic similarity between the query and\ndocuments, making it highly effective for open-domain question-answering tasks. The strength of DPR\nlies in its ability to retrieve relevant information based on semantic meaning rather than keyword\nmatching. By training the retriever on a large corpus of question-answer pairs, DPR can finddocuments\nthat are contextually related to the query, even when the query and the document do not share exact\nterms. Recent research has further improved DPRbyintegratingitwithpre-trainedlanguagemodelsand", "metadata": {"id": "ed2a699fd32b835b22ef7cfc90a15992ef361a6d", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "terms. Recent research has further improved DPRbyintegratingitwithpre-trainedlanguagemodelsand\nanexampleisLLMadaptedforthedenseRetrievAlapproach(Liet.al.2023)\n2.2.3REALM(Retrieval-AugmentedLanguageModel)\nAnother significant advancement in retrieval mechanisms for RAG models is REALM (Guu et al.(2020).\nREALM integrates retrieval into the language model's pre-training process, ensuring that the retriever is\noptimized alongside the generator for downstreamtasks.ThekeyinnovationinREALMisthatitlearnsto", "metadata": {"id": "63fe4aec59b1279e1b38b4dc9a93a108546fbb1e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "optimized alongside the generator for downstreamtasks.ThekeyinnovationinREALMisthatitlearnsto\nretrieve documents that improve the model’s performance on specific tasks, suchasquestionanswering\nor document summarization. During training, REALM updates both the retriever and the generator,\nensuring that the retrieval process is optimized for the generation task. REALM’s retriever is trained to\nidentify documents that are not only relevant to the query but also helpful for generating accurate and\ncoherent responses. As a result, REALM significantly improves the quality of generated responses,", "metadata": {"id": "6199e2c6e504dcb605015c81965b2e31a3fde869", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "coherent responses. As a result, REALM significantly improves the quality of generated responses,\nparticularly in tasks that require external knowledge. Recent studies have demonstrated that REALM\noutperforms both BM25 and DPR in certain knowledge-intensive tasks, particularly when retrieval is\ntightlycoupledwithgeneration.\nThe core of RAG lies in the quality of retrieved passages, but many current methods rely on\nsimilarity-based retrieval (Mallen et al. 2022). Self-RAG (Asai et al. 2023b), and REPLUG (Shi et al.,", "metadata": {"id": "7dd0aabd87057f64937194bfc817dfeaae29411f", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "2023) have advanced by leveraging LLMs to enhance retrieval capabilities, achieving more adaptive\nretrieval. After initial retrieval, cross-encoder models are used to re-rank the retrieved results by jointly\nencoding the query and each retrieved document to compute relevance scores. These models provide\nmore context-aware retrieval at the cost of higher computational overhead. Pointwise and Pairwise\nRanking, often based on Learning-to-Rank (LTR) algorithms, are used to assign relevance scores to", "metadata": {"id": "ab43cc55968c5d41eb64fb1e49fb4e4c0b06fa2f", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 6, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "retrieved documents, either independently (pointwise) or by comparing document pairs (pairwise). RAG\nsystems utilizeself-attentionwithintheLLMtomanagecontextandrelevanceacrossdifferentpartsofthe\ninput and retrieved text. Cross-attentionmechanismsareusedwhenintegratingretrievedinformationinto\nthe generative model, ensuring that the most relevant pieces of information are emphasized during\ngeneration.\n2.3GeneratorMechanismsinRAGSystems\nIn Retrieval-Augmented Generation (RAG) systems, the generator mechanism plays a crucial role in", "metadata": {"id": "914167570d29c90463670aaa8c1334581f093089", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "In Retrieval-Augmented Generation (RAG) systems, the generator mechanism plays a crucial role in\nproducing the final output by integrating retrieved information with the input query. After the retrieval\ncomponent pulls relevant knowledge from external sources, the generator synthesizes this information\ninto coherent, contextually appropriate responses. The Large Language Model (LLM) serves as the\nbackbone of the generator, which ensures the generated text is fluent, accurate, and aligned with the\noriginalquery.\n2.3.1T5(Text-to-TextTransferTransformer)", "metadata": {"id": "abeb0055a1df624f24d3a17f16b1c2cee66ceace", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "originalquery.\n2.3.1T5(Text-to-TextTransferTransformer)\nT5 (Text-to-Text Transfer Transformer) (Raffel et al. 2020) is one of the most commonlyusedmodelsfor\ngeneration tasks in RAG systems. T5isversatileinitsapproach,framingeveryNLPtaskasatext-to-text\ntask. This uniform framework allows T5 to be fine-tuned for a wide range of tasks, including\nquestion-answering, summarization, and dialogue generation. By integrating retrieval with generation,\nT5-based RAG models have been shown to outperform traditional generative models like GPT-3 and", "metadata": {"id": "465d1c4c84e2728470b33c75f98c055d716ce9ff", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "T5-based RAG models have been shown to outperform traditional generative models like GPT-3 and\nBART on several benchmarks, including the Natural Questions dataset and the TriviaQA dataset.\nMoreover, T5's ability to handle complex multi-task learning makes it a popular choice for RAG systems\nthatneedtotackleadiverserangeofknowledge-intensivetasks.\n2.3.2BART\nBART(BidirectionalandAuto-RegressiveTransformer),introducedbyLewisetal.(2020),isanother\nprominentgenerativemodelusedinRAGsystems.BARTisparticularlywell-suitedfortasksinvolvingtext", "metadata": {"id": "c7f1f0137fdda0dca62c1e9b71289a2fdf22a278", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "prominentgenerativemodelusedinRAGsystems.BARTisparticularlywell-suitedfortasksinvolvingtext\ngenerationfromnoisyinputs,suchassummarizationandopen-domainquestionanswering.Asa\ndenoisingautoencoder,BARTcanreconstructcorruptedtextsequences,makingitrobustfortasksthat\nrequirethegenerationofcoherent,factualoutputsfromincompleteornoisydata.Whenpairedwitha\nretrieverinaRAGsystem,BARThasbeenshowntoimprovethefactualaccuracyofgeneratedtextby\ngroundingitinexternalknowledge.StudieshavedemonstratedthatBART-basedRAGmodelsachieve", "metadata": {"id": "6dc75bed0c9139a9d8913aa1dc0e651f15f2bc87", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "groundingitinexternalknowledge.StudieshavedemonstratedthatBART-basedRAGmodelsachieve\nstate-of-the-artresultsinvariousknowledge-intensivetasks,includingdialoguegenerationandnews\nsummarization.\n3.Retrieval-AugmentedGenerationModelsAcrossDifferentModalities\n3.1 Text-Based RAG Models: Text-based RAG models represent the most mature and widely\nresearched category. These models leverage textual data for both retrieval and generation tasks,\nenabling applications such as question-answering, summarization, and conversational agents.", "metadata": {"id": "54a6edaea9972b6b6d7efe3a406e4a4889b67b7a", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "enabling applications such as question-answering, summarization, and conversational agents.\nTransformer architectures, such as BERT (Devlin et al., 2019) and T5 (Raffel et al., 2020), are\nfoundational in text-based RAG models. These models utilize self-attention mechanisms to capture\ncontextual relationships within text, which enhances both retrieval accuracy and generation fluency.\nDense retrieval models, such as those using dense embeddings from BERT, offer superior performance\ncompared to traditional sparse methods like TF-IDF. Dense retrievers (Karpukhin et al. 2020), leverage", "metadata": {"id": "e1b0649c5818a381a7927d6ed16919eee4575cec", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "dense representations to retrieve relevant documents more effectively. Recent advancements focus on\nintegrating retrieval and generation into a single training pipeline. REALM (Guu et al., 2020) is an", "metadata": {"id": "b312d17aeecf1951d1adb4432fbec84dbe5574a7", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 7, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "example of such anend-to-endmodelthatjointlyoptimizesretrievalandgenerationprocesses,improving\noveralltaskperformance.\n3.2 Audio-Based RAG Models: Audio-based RAG models extend the principles of retrieval-augmented\ngeneration to the audio modality,enablingapplicationssuchasspeechrecognition,audiosummarization,\nand conversational agents in voice interfaces. Audiodataisoftenrepresentedusingembeddingsderived\nfrom pre-trained models like Wav2Vec 2.0 (Baevski et al., 2020). These embeddings serve as input to\nretrievalandgenerationcomponents,enablingthemodeltohandleaudiodataeffectively.", "metadata": {"id": "c1379a5dbd5b48cf62f018ef10301451869189ab", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 8, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "retrievalandgenerationcomponents,enablingthemodeltohandleaudiodataeffectively.\n3.3 Video-Based RAG Models: Video-based RAG models incorporate both visual and textual\ninformation to enhance performance in tasks such as video understanding, captioning, and retrieval.\nVideo data is represented using embeddings from models like I3D (Xie et. al. 2017) or TimeSformer\n(Bertasius et al. 2021). These embeddings capture temporal and spatial features essential for effective\nretrievalandgeneration.\n3.4 Multimodal RAG Models: Multimodal RAG models integrate data from multiple modalities—text,", "metadata": {"id": "a2442ef48c6db552dc6e0ec02d1f25e09e3d9159", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 8, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "3.4 Multimodal RAG Models: Multimodal RAG models integrate data from multiple modalities—text,\naudio, video, and images—to provide a more holistic approach to retrieval andgenerationtasks.Models\nlike Flamingo (Alayrac et al., 2022) integrate multiple modalities into a unified framework, enabling\nsimultaneous processing of text, images, and videos. Techniques for cross-modal retrieval involve\nretrievingrelevantinformationacrossdifferentmodalities(Li.et.al.2023).\nMultimodal capabilities enhance the versatility and efficiency of RAG across various applications.”", "metadata": {"id": "b407b4865d568c3b1ccd9a34e1e82a85045f79b5", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 8, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Multimodal capabilities enhance the versatility and efficiency of RAG across various applications.”\nRetrieval as generation” (Wang et. al. 2024) extends the Retrieval-Augmented Generation (RAG)\nframework tomultimodalapplicationsbyincorporatingtext-to-imageandimage-to-textretrieval.Utilizinga\nlarge dataset of pairedimagesandtextdescriptions,thesystemacceleratesimagegenerationwhenuser\nqueries align with stored text descriptions (\"retrieval as generation\"). The image-to-text functionality\nallowsuserstoengageindiscussionsbasedoninputimages.", "metadata": {"id": "56736a7b9cd9b3e6c645dac065e4f002c8e7da6c", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 8, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "allowsuserstoengageindiscussionsbasedoninputimages.\nFigure3:TimelineoftheevolutionoftheRAGsystemanditscomponents", "metadata": {"id": "723697ec3f1ab1fdf04487d88404cb10ae5b2753", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 8, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "4.RecentAdvancementinthefield:\nThere has been significant advancement in this field and this section intendstocapturekeyfindingsofa\nfew important recent papers.AnovelagenticRetrieval-AugmentedGeneration(RAG)framework(Ravuru\net. al. 2024) employs a hierarchical,multi-agentarchitecturewherespecializedsub-agents,usingsmaller\npre-trained language models (SLMs), are fine-tuned for specific time series tasks. The master agent\ndelegates tasks to these sub-agents, who retrieve relevant prompts fromasharedknowledgerepository.", "metadata": {"id": "f89c918045983142b186a27c9285e3fcab367d74", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 9, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "delegates tasks to these sub-agents, who retrieve relevant prompts fromasharedknowledgerepository.\nIn this modular, multi-agent approach, the authors achieve state-of-the-art performance demonstrating\nimproved flexibility and effectiveness over task-specificmethodsintimeseriesanalysis.RULE(Xiaet.al.\n2024), a multimodal Retrieval-Augmented Generation (RAG) framework designed to improve the\nfactuality of medical Vision-Language Models (Med-LVLM), addresses challenges in medical RAG by\nintroducing a calibrated selection strategy to control factuality risk, and, by developing a preference", "metadata": {"id": "9e8acf410e3d9e28a9e362aca723b3351b26a73d", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 9, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "optimization strategy to balance the model’s intrinsic knowledge with retrieved contexts, proving its\neffectiveness in enhancing factual accuracy in Med-LVLM systems. METRAG (Gan et. al. 2024), a\nmulti-layered, thoughts-enhanced retrieval-augmented generation framework,integratesLLMsupervision\nto generate utility-oriented thoughts and combines document similarity with utility for improved\nperformance. It also incorporates a task-adaptive summarizer to produce compact thoughts. Using the\nmulti-layered thoughts from these stages, an LLM generates knowledge-augmented content,", "metadata": {"id": "44c937b44b17fab84b5c54ae33e3e5f1a1f860b0", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 9, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "multi-layered thoughts from these stages, an LLM generates knowledge-augmented content,\ndemonstrating superior performance on knowledge-intensive tasks compared to traditional approaches.\nDistractordocumentis\nFigure4:EvolvingTrendsinRAGcapturedfromresearchpapers", "metadata": {"id": "6555614c1e5d4e2986e53e100945a7e92e26764a", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 9, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "one of the key traits of Retrieval AugmentedFine-Tuning(RAFT)(Zhanget.al.2024)wherethemodelis\ntrained to disregard irrelevant, distractor documents and instead cite directly from relevant sources.This\nprocess, combined with a chain-of-thought reasoning style, enhances themodel'sreasoningcapabilities.\nRAFT demonstrates consistent performance improvements in domain-specific RAG tasks, including\nPubMed, HotpotQA, and Gorilla datasets, serving as a post-training enhancement for LLMs. FILCO\n(Wang et. al. 2023) , a method designed toenhancethequalityofcontextprovidedtogenerativemodels", "metadata": {"id": "24d58080d7398d54936c794d58f150f1b1dc49e8", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "(Wang et. al. 2023) , a method designed toenhancethequalityofcontextprovidedtogenerativemodels\nin tasks like open-domain question answering and fact verification, addresses issues of over- or\nunder-relianceonretrievedpassages,whichcanleadtoproblemssuchashallucinationsinthegenerated\noutputs. The method improves context quality by identifying useful context through lexical and\ninformation-theoretic approaches and training context filtering models to refine retrieved contexts during\ntesttime.ReflectionTokenisakeyattributeofSelf-reflectiveRetrievalAugmented-Generation(Self-RAG)", "metadata": {"id": "b22c71d4c415a85bf20e437b465a75a2e5d40a82", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "testtime.ReflectionTokenisakeyattributeofSelf-reflectiveRetrievalAugmented-Generation(Self-RAG)\n(Asai et. al. 2023),anovelframeworkdesignedtoimprovethefactualaccuracyoflargelanguagemodels\n(LLMs) by combining retrieval with self-reflection. Unlike traditionalmethodsthatretrieveandincorporate\na fixed number of passages, Self-RAG adaptively retrievesrelevantpassagesandusesreflectiontokens\nto evaluate and refine its responses, allowing the model to adjust its behavior according to task-specific\nneeds and has shown superior performance in open-domain question-answering, reasoning, fact", "metadata": {"id": "370286760dca24eaacf6c7e0b7bf39d858311483", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "needs and has shown superior performance in open-domain question-answering, reasoning, fact\nverification, and long-formgenerationtasks.IntelligenceandeffectivenessofRAGaredependentaloton\nthe quality of retrieval and more meta-data understanding of the repository would enhance the\neffectiveness of the RAG system. A novel data-centric Retrieval-Augmented Generation (RAG)workflow\nadvances beyond the traditional retrieve-then-read mode and employs a\nprepare-then-rewrite-then-retrieve-then-read framework, enhancing LLMs by integrating contextually", "metadata": {"id": "6a9d27ed4190458c65aea8df8e05934da7b55212", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "prepare-then-rewrite-then-retrieve-then-read framework, enhancing LLMs by integrating contextually\nrelevant, time-critical, or domain-specific information. Key innovations include generating metadata,\nsynthetic Questions and Answers (QA), and introducing the Meta Knowledge Summary (MK Summary)\nfor clusters of documents (Mombaerts et. al. 2024). A recent paper introduces CommunityKG-RAG\n(Chang et. al. 2024), a zero-shot framework that integrates community structures within Knowledge\nGraphs (KGs) into Retrieval-Augmented Generation (RAG) systems. This approach enhances the", "metadata": {"id": "dfad0a83e557aa614c35afaa96834a596a0dc29c", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Graphs (KGs) into Retrieval-Augmented Generation (RAG) systems. This approach enhances the\naccuracy and contextual relevance of fact-checking by utilizing multi-hop connections within KGs,\noutperforming traditional methods without requiring additional domain-specific training. The RAPTOR\nmodel (Sarthi et. al. 2024) introduces a hierarchical approach to retrieval-augmented language models,\naddressing limitations in traditional methods that retrieve only short, contiguous text chunks. RAPTOR\nforms a summary tree to retrieve information at varying abstraction levels by recursively embedding,", "metadata": {"id": "03048aa4a804f2bc7c09f671acdaabf42bf4af33", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "clustering, and summarizing text. Experiments demonstrate RAPTOR’s superior performance,especially\nin question-answering tasks requiring complex reasoning. When paired with GPT-4, RAPTOR improves\naccuracyontheQuALITYbenchmarkby20%.\nThis advancement in RAGfurtherprovestheutilityoftheRAGsystemhoweverrecentLLMlaunchesthat\nsupport long-term context havesignificantlyshownimprovedperformance.Arecentstudy(Liet.al.2024)\ncompared the efficiency of Retrieval Augmented Generation (RAG) and long-context (LC) Large\nLanguage Models (LLMs), such as Gemini-1.5 and GPT-4. While LC models outperform RAG when", "metadata": {"id": "125b2efae4d4e7e53b3279c2e1dec955a3accbeb", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Language Models (LLMs), such as Gemini-1.5 and GPT-4. While LC models outperform RAG when\nadequately resourced, RAG's cost-efficiency remains advantageous. To balance performance and cost,\nthe paper introduces Self-Route. This method dynamically directs queries to either RAG orLCbasedon\nmodel self-reflection, optimizing both computation cost and performance. This study offers valuable\ninsights into the optimal application of RAG and LC in handling long-context tasks. Nguyen et. al., 2024\nintroduce SFR-RAG , a small but highly efficientRetrievalAugmentedGeneration(RAG)model,whichis", "metadata": {"id": "98085d95fd21194e6989308348294c1fbe15c450", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "introduce SFR-RAG , a small but highly efficientRetrievalAugmentedGeneration(RAG)model,whichis\ndesigned to enhance the integration of external contextual information into Large Language Models\n(LLMs) while minimizing hallucinations. LA-RAG (Li et. al., 2024), a novel Retrieval-Augmented\nGeneration (RAG) paradigm designed to enhance Automatic Speech Recognition (ASR) in large\nlanguage models (LLMs). One of the key benefits of LA-RAG is its ability to leverage fine-grained\ntoken-level speech data stores alongside a speech-to-speech retrieval mechanism, improving ASR", "metadata": {"id": "5f7d55a146454715d0cd37c6d811b61424610295", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 10, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "accuracy by incorporating LLM in-context learning (ICL). The studyfocusesondatasetsofMandarinand\nvarious Chinese dialects, demonstrating significant accuracy improvements, particularly in managing\naccent variations, which have historically been a challenge for existing speech encoders. The findings\nhighlight LA-RAG’s potential to advance ASR technology, offering a more robust solution for diverse\nacoustic conditions. Large Language Models (LLMs) face challenges in AI legal and policy contextsdue\nto outdated knowledge and hallucinations. HyPA-RAG (Kalra et. al., 2024),aHybridParameter-Adaptive", "metadata": {"id": "1680bbf52ae9ebe8f5da3265fb3facf17bde5c6e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "to outdated knowledge and hallucinations. HyPA-RAG (Kalra et. al., 2024),aHybridParameter-Adaptive\nRetrieval-Augmented Generation system, improves accuracy by using adaptive parameter tuning and\nhybrid retrieval strategies. Tested on NYC Local Law 144 (LL144), HyPA-RAG demonstrates enhanced\ncorrectness and contextual precision, addressing the complexities oflegaltexts.MemoRAG(Qianet.al.,\n2024) introduces a novel Retrieval-Augmented Generation (RAG) paradigm designed to overcome the\nlimitations of traditional RAG systems in handling ambiguous or unstructured knowledge. MemoRAG’s", "metadata": {"id": "6dbad63b2fdd12b7fdf3c3267186f18643ef094d", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "limitations of traditional RAG systems in handling ambiguous or unstructured knowledge. MemoRAG’s\ndual-system architecture utilizes a lightweight long-range LLM to generate draft answers and guide\nretrieval tools, while a more powerful LLM refines the final output. This framework, optimized for better\ncluing and memory capacity, significantly outperforms conventional RAG models across both complex\nand straightforward tasks. NLLB-E5 (Acharya et. al., 2024) introduces a scalable multilingual retrieval\nmodel aimed at addressing the challenges faced in supporting multiple languages, particularly", "metadata": {"id": "28bb50d062ffe1af737334015695c5ff6fea9895", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "model aimed at addressing the challenges faced in supporting multiple languages, particularly\nlow-resource languages like Indiclanguages.ByleveragingtheNLLBencoderandadistillationapproach\nfromtheE5multilingualretriever,NLLB-E5enableszero-shotretrievalacrosslanguageswithouttheneed\nfor multilingual training data. Evaluations on benchmarks such as Hindi-BEIR showcase its robust\nperformance, highlighting task-specific challenges and advancing multilingual information access for\nglobalinclusivity.\n5.CurrentChallenges andLimitationsinRetrieval-AugmentedGeneration(RAG):", "metadata": {"id": "5ea6e7c26bf51526f823e1350bba8b1241224cf8", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "globalinclusivity.\n5.CurrentChallenges andLimitationsinRetrieval-AugmentedGeneration(RAG):\nThissectionintendstohighlightthecurrentchallengesandlimitationsofRAGconsideringthecurrent\nlandscapeofthesystemandthiswouldshapethefutureresearchdirectionsinthefield.\nScalability and Efficiency: One of the primary challenges for RAG models is scalability. As retrieval\ncomponentsrelyonexternaldatabases,handlingvastanddynamicallygrowingdatasetsrequiresefficient\nretrieval algorithms. High computational costs and memory requirements also make it difficult to deploy", "metadata": {"id": "c19ca8f99337ebe7f8b048a8af7353e1dd53cc1e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "RAGmodelsinreal-timeorresource-constrainedenvironments(Shietal.2023),(Asaietal.2023b).\nRetrieval Quality and Relevance: Ensuring the quality andrelevanceofretrieveddocumentsremainsa\nsignificant concern. Retrieval models can sometimes return irrelevant or outdated information, which\nnegatively affects the accuracy of the generated output. Improving retrieval precision, especially for\nlong-formcontentgeneration,remainsanactiveareaofresearch(Mallenetal.2022),(Shietal.2023).\nBias and Fairness: Similar to other machine learning models, RAG systems can exhibit bias due to", "metadata": {"id": "80ca8be67f2a0ad68930073dd27653fa3e1fea18", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Bias and Fairness: Similar to other machine learning models, RAG systems can exhibit bias due to\nbiases present in the retrieved datasets. Retrieval-based models may amplifyharmfulbiasesinretrieved\nknowledge, leading to biased outputs in a generation. Developing bias mitigation techniquesforretrieval\nandgenerationintandemisanongoingchallenge.\nCoherence: RAG models often struggle with integrating the retrieved knowledge into coherent,\ncontextually relevant text. The alignment between retrieved passages and the generationmodel'soutput", "metadata": {"id": "afc0484eb6a4c693cd3001666673f94d0ea222da", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "is not always seamless, leading to inconsistencies or factual hallucinations in the finalresponse(Jietal.\n2022).", "metadata": {"id": "8643920bab8c43d91dc5ae16f7232e7241a584be", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 11, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Interpretability and Transparency: Like many AI systems, RAG models are often treated as black\nboxes, with limited transparency in how retrieval influences generation. Improving the interpretability of\nthesemodelsiscrucialtofosteringtrust,especiallyincriticalapplications(Rolleretal.2020).\n6.FutureResearchDirectionsforRetrieval-AugmentedGeneration(RAG)\nRetrieval-augmented generation (RAG) represents a significant advancement in natural language\nprocessing and related fields by combining retrieval and generative mechanisms. This section explores", "metadata": {"id": "2d736c9d48abe2ceb16c2d3c629425100b28c041", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "keyareasforfutureresearch,highlightingthepotentialforinnovationandimprovementinRAGsystems.\n6.1 Enhancing Multimodal Integration: The integration of text, image, audio, and video data in RAG\nmodels remains an evolving challenge. Future research should focus on improving multimodal fusion\ntechniques to enable seamless interaction between different data types. This includes developing\nadvanced methods for aligning and synthesizing information across modalities. Recent works (Chen et.\nal. 2022), (Yasunaga et. al. 2022), (Zhu et. al. 2024) have explored multimodal learning, but further", "metadata": {"id": "9fe8ded9e190bb50ba444db54ace5a3fe8051f63", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "innovations are needed to enhance the coherence andcontextualityofmultimodaloutputs.Researchinto\ncross-modal retrieval aims to improve the ability of RAG systems to retrieve relevant information across\ndifferent modalities. For example, combining text-based queries with image or video content retrieval\ncould enhance applications such as visual question answering and multimedia search. This is another\nfuturedirectiontoexploreforRAGrelatedresearch.\n6.2 Scaling and Efficiency: As RAG models are deployed in increasingly large-scale applications,", "metadata": {"id": "1313207f1e50b26a1d3b042fd5c5b416fe4a8f9d", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "6.2 Scaling and Efficiency: As RAG models are deployed in increasingly large-scale applications,\nscalability becomes a critical concern. Research should focus on developing methods toefficientlyscale\nretrieval and generation processes without compromising performance. Techniques such as distributed\ncomputing and efficient indexing methods are essential for handling large datasets. Improving the\nefficiency of RAG models involves optimizing both retrieval and generation components to reduce\ncomputationalresourcesandlatency.", "metadata": {"id": "e72348a8af2922af83a69139fa28495c4837e8b7", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "computationalresourcesandlatency.\n6.3 Personalization and Adaptation: Future RAG models should focus on personalizing retrieval\nprocesses to cater to individual user preferences and contexts. This involves developing techniques to\nadapt retrieval strategies based on user history, behaviour, and preferences. Enhancing the contextual\nadaptation of RAG models by deeper understandingofthecontextandsentimentsofquery(Guptaet.al.\n2024) and the repository of ducments is crucial for improving the relevance of generated responses.", "metadata": {"id": "41cacf51f9ee4579b835d5dc6c7fbeb1ee6d9896", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "2024) and the repository of ducments is crucial for improving the relevance of generated responses.\nResearch should explore methods for dynamic adjustment of retrieval and generation processes based\nontheevolvingcontextofinteractions.Thisincludesincorporatinguserfeedbackandcontextualcuesinto\ntheRAGpipeline.\n6.4 Ethical and PrivacyConsiderations:Addressingbiases(Shresthaet.al.2024),(Guptaet.al.2024)\nin general and specifics to RAG models is a critical area for future research. As RAG systems are", "metadata": {"id": "22301862470d9b31044c3b3e3080e0dcc9305804", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "in general and specifics to RAG models is a critical area for future research. As RAG systems are\ndeployed in diverse applications, ensuring fairness and mitigating biases in retrieved and generated\ncontent is essential. Future RAG research should focus on privacy-preserving techniques to protect\nsensitive information during retrieval and generation. This includes developing methods for secure data\nhandling and privacy-aware retrieval strategies. Interpretability of model is also a critical area to focus\nuponasapartofongoingresearchinimprovingRAG.", "metadata": {"id": "22eb9da7681c602b27be789a22cd7a5fe9c7766c", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "uponasapartofongoingresearchinimprovingRAG.\n6.5 Cross-Lingual and Low-Resource Languages: Expanding RAG technology to support multiple\nlanguages ( Chirkova et. al. 2024), especially low-resource languages, is a promising direction. Future", "metadata": {"id": "10dc2c3bb947ae880a912c29257a6ce797ca285e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 12, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "research should aim toimprovecross-lingualretrievalandgenerationcapabilitiestoprovideaccurateand\nrelevant results across different languages. Enhancing RAG models to effectively support low-resource\nlanguages involves developing methods to retrieve and generate content with limited training data.\nResearch should focus on techniques for transfer learning and data augmentation to improve\nperformanceinunderrepresentedlanguages.\n6.6 Advanced Retrieval Mechanisms: Future RAG research should explore dynamic retrieval", "metadata": {"id": "a34bf1012c8a1d6ceafb8682a8bd42a6dabe5e02", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "6.6 Advanced Retrieval Mechanisms: Future RAG research should explore dynamic retrieval\nmechanisms that adapt to changing query patterns and content requirements. This includes developing\nmodels that can dynamically update theirretrievalstrategiesbasedonnewinformationandevolvinguser\nneeds. Investigating hybrid retrieval approaches that combine various retrievalstrategies,suchasdense\nand sparse retrieval, could enhance the effectiveness of RAG systems. Research shouldexplorehowto\nintegratedifferentretrievalmethodstoachieveoptimalperformancefordiversetasks.", "metadata": {"id": "be89ea181279066be4c08d2bef115cca66ce4200", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "integratedifferentretrievalmethodstoachieveoptimalperformancefordiversetasks.\n6.7 Integration with Emerging Technologies: Integrating RAG models with brain-computer interfaces\n(BCIs) could lead to novel applications in human-computer interaction and assistive technologies.\nResearch should explore how RAG systems can leverage BCI data to enhance user experience and\ngenerate context-aware responses.The integration of RAG with AR and VR technologies presents\nopportunities for creating immersive and interactive experiences.Futureresearchshouldinvestigatehow", "metadata": {"id": "e62395666725b3524311a59fb8218e2d815475e6", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "opportunities for creating immersive and interactive experiences.Futureresearchshouldinvestigatehow\nRAG models can be used to enhance AR and VR applications by providing contextually relevant\ninformationandinteractions.\n7.Conclusion\nRetrieval-Augmented Generation (RAG) has undergone significant evolution, with extensive research\ndedicated to improving retrieval effectiveness and enhancing coherent generation to minimize\nhallucinations.Fromitsearlyiterationstorecentadvancements,RAGhasbeeninstrumentalinintegrating", "metadata": {"id": "e36bfaf7135ac486a7a0f1f63e6b95580cf49064", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "hallucinations.Fromitsearlyiterationstorecentadvancements,RAGhasbeeninstrumentalinintegrating\nexternal knowledge into Large Language Models (LLMs), thereby boosting accuracy and reliability. In\nparticular, recent domain-specific work has showcased RAG's potential in specialized areas such as\nlegal, medical, and low-resource language applications, highlighting its adaptability andscope.However,\ndespite these advances, this paper identifies clear gaps that remain unresolved. Challengessuchasthe", "metadata": {"id": "e5027993f219d62de9a40ed2101df26de60ea01d", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "integration of ambiguous or unstructured information, effective handling of domain-specific contexts,and\nthe high computational overhead of complex retrieval tasks still persist. These limitations constrain the\nbroader applicability of RAG systems, particularly in diverse and dynamic real-world environments. The\nfuture research directions outlined in this paper—ranging from improving retrieval mechanisms to\nenhancing context management and ensuring scalability—will serveasacriticalguideforthenextphase", "metadata": {"id": "a304741cf79d580b10a2978d485b4d70c073fcc0", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "enhancing context management and ensuring scalability—will serveasacriticalguideforthenextphase\nof innovation in this space. By addressing these gaps, the next generation of RAG models has the\npotential to drive more reliable, efficient, and domain-adaptable LLM systems, further pushing the\nboundariesofwhatispossibleinretrieval-augmentedAIapplications.", "metadata": {"id": "adee29ccca0e10233999299382cd864c35519f0a", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 13, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "References:\nAcharya, A., Murthy, R., Kumar, V., & Sen, J. (2024). NLLB-E5: A Scalable Multilingual Retrieval Model.\nArXiv./abs/2409.05401\nAlayrac, J., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K.,\nReynolds, M., Ring, R., Rutherford, E., Cabi, S., Han, T., Gong, Z., Samangooei, S., Monteiro, M.,\nMenick, J., Borgeaud, S., . . . Simonyan, K. (2022). Flamingo: A Visual Language Model for Few-Shot\nLearning.ArXiv./abs/2204.14198\nAsai, A., Wu, Z., Wang, Y., Sil, A., & Hajishirzi, H. (2023). Self-RAG: Learning to retrieve, generate,and", "metadata": {"id": "8055688029d16b3d0d072b020378af640f27f551", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 14, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "critiquethroughself-reflection.arXivpreprintarXiv:2310.11511.\nBaevski, A., Zhou, H., Mohamed, A., & Auli, M. (2020). Wav2vec 2.0: A Framework for Self-Supervised\nLearningofSpeechRepresentations.ArXiv./abs/2006.11477\nBertasius, G., Wang, H., & Torresani, L. (2021). Is Space-Time Attention All You Need for Video\nUnderstanding?ArXiv./abs/2102.05095\nBinns, R. (2018). Fairness in machine learning: Lessons from political philosophy. Proceedings of the\n2018ConferenceonFairness,Accountability,andTransparency(pp.149-159).", "metadata": {"id": "c81f0d69f93a5b91a48157fca4f7aceae6101147", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 14, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "2018ConferenceonFairness,Accountability,andTransparency(pp.149-159).\nBorgeaud, S., Mensch, A.,Hoffmann,J.,Cai,T.,Rutherford,E.,Millican,K.,Driessche,G.V.,Lespiau,J.,\nDamoc, B., Clark, A., Casas, D. D., Guy, A., Menick, J., Ring, R.,Hennigan,T.,Huang,S.,Maggiore,L.,\nJones, C., Cassirer, A., . . . Sifre, L. (2021). Improving language models by retrieving from trillions of\ntokens.ArXiv./abs/2112.04426\nBrown,T.,etal.(2020).\"LanguageModelsareFew-ShotLearners.\"arXivpreprintarXiv:2005.14165.\nChang, R., & Zhang, J. (2024). CommunityKG-RAG: Leveraging Community Structures in Knowledge", "metadata": {"id": "13246d9bc9b967ba0dbf1aeb9be8d799382945bc", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 14, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Chang, R., & Zhang, J. (2024). CommunityKG-RAG: Leveraging Community Structures in Knowledge\nGraphsforAdvancedRetrieval-AugmentedGenerationinFact-Checking.ArXiv./abs/2408.08535\nChen, D., Fisch, A., Weston, J., & Bordes, A. (2017). Reading Wikipedia to answer open-domain\nquestions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics\n(Volume1:LongPapers)(pp.1870-1879).\nChen, W., Hu, H., Chen,X.,Verga,P.,&Cohen,W.W.(2022).MuRAG:MultimodalRetrieval-Augmented\nGeneratorforOpenQuestionAnsweringoverImagesandText.ArXiv./abs/2210.02928", "metadata": {"id": "00594ef6fc9c90cf9bc2653a9a305cf7e4c9bfed", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 14, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "GeneratorforOpenQuestionAnsweringoverImagesandText.ArXiv./abs/2210.02928\nChirkova, N., Rau, D., Déjean, H., Formal, T., Clinchant, S., & Nikoulina,V.(2024).Retrieval-augmented\ngenerationinmultilingualsettings.ArXiv./abs/2407.01463\nDai, Z., & Callan, J. (2019). Context-Aware Sentence/Passage Term Importance Estimation For First\nStageRetrieval.ArXiv./abs/1910.10687\nDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional\ntransformers for language understanding. In Proceedings of the 2019 Conference oftheNorthAmerican", "metadata": {"id": "63973475f3ed65106b53b6464454324a13220b30", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 14, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "transformers for language understanding. In Proceedings of the 2019 Conference oftheNorthAmerican\nChapter of the Association for Computational Linguistics: Human Language Technologies (pp.\n4171-4186).", "metadata": {"id": "ba540d0cd3344d8db30dbb94fe9ec0c6a389910c", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 14, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional\nTransformersforLanguageUnderstanding.ArXiv./abs/1810.04805\nGan, C., Yang, D., Hu, B., Zhang, H., Li, S., Liu,Z.,Shen,Y.,Ju,L.,Zhang,Z.,Gu,J.,Liang,L.,&Zhou,\nJ. (2024). Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered\nThoughts.ArXiv./abs/2405.19893\nGatt,A.,&Krahmer,&E.(2018).Surveyofthestateoftheartinnaturallanguagegeneration:Coretasks,\napplications,andevaluation.JournalofArtificialIntelligenceResearch,61,65-170.", "metadata": {"id": "7dc13c6241c600837d97049c73a87519074e4da1", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 15, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "applications,andevaluation.JournalofArtificialIntelligenceResearch,61,65-170.\nGupta, S., & Ranjan, R. (2024). Evaluation of LLMs Biases TowardsEliteUniversities:APersona-Based\nExploration.ArXiv./abs/2407.12801\nGupta, S., Ranjan, R., & Singh, S. N. (2024). Comprehensive Study on Sentiment Analysis: From\nRule-basedtomodernLLMbasedsystem.ArXiv./abs/2409.09989\nGuu, J., Lee, K., & Pasupat, P. (2020). Retrieval-augmented generation for knowledge-intensive NLP\ntasks.arXivpreprint.https://arxiv.org/abs/2002.08909", "metadata": {"id": "3e12c8a25a0b5a82e625ed8b50917454248e65f8", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 15, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "tasks.arXivpreprint.https://arxiv.org/abs/2002.08909\nGuu, K., Lee, K., Tung, Z., Pasupat, P., & Chang, M. (2020). REALM: Retrieval-augmented language\nmodel pre-training. In Proceedings of the 37th International Conference on Machine Learning (pp.\n3929-3938).\nHan, S., Pool, J., Tran, J., & Dally, W. J. (2015). Learning both weights and connections for efficient\nneuralnetwork.InAdvancesinNeuralInformationProcessingSystems(pp.1135-1143).\nIzacard, G., & Grave, E. (2021). Leveraging passage retrieval with generative models for open domain", "metadata": {"id": "ea5b2c6daa4d26a3e659b870a79fffe784d52950", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 15, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "question answering. In Proceedings of the 16th Conference of the European Chapter of the Association\nforComputationalLinguistics:MainVolume(pp.874-880).\nJi, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Chen, D., Dai, W., Chan, H. S.,\nMadotto, A., & Fung, P. (2022). Survey of Hallucination in Natural Language Generation. ArXiv.\nhttps://doi.org/10.1145/3571730\nKalra, R., Wu, Z., Gulley, A., Hilliard, A., Guan, X., Koshiyama,A.,&Treleaven,P.(2024).HyPA-RAG:A\nHybridParameterAdaptiveRetrieval-AugmentedGenerationSystemforAILegalandPolicyApplications.\nArXiv./abs/2409.09046", "metadata": {"id": "93f99a153159227d79f25c13fd01f3588a2483b8", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 15, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "ArXiv./abs/2409.09046\nKarpukhin, V., Oguz, B., Min, S., & Yih, W. (2020). Dense passage retrieval for open-domain question\nanswering.arXivpreprint.https://arxiv.org/abs/2004.04906\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D. & Yih, W. T. (2020). Dense\npassage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on\nEmpiricalMethodsinNaturalLanguageProcessing(EMNLP)(pp.6769-6781).\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Riedel, S. (2020).", "metadata": {"id": "116a57f1d44bf6ef2cdd9485b67a362bc03f3a03", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 15, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Riedel, S. (2020).\nRetrieval-augmented generation for knowledge-intensive NLP tasks. In Proceedings of the 34th\nInternationalConferenceonNeuralInformationProcessingSystem(pp.9459-9474).", "metadata": {"id": "1d07ff9650188652e89a6b26b204705e9faff2e7", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 15, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Li, C., Liu, Z., Xiao, S., & Shao, Y. (2023). Making Large Language Models A Better Foundation For\nDenseRetrieval.ArXiv./abs/2312.15503\nLi, F., Zhu, L., Wang, T., Li, J., Zhang, Z., & Shen, H. T. (2023). Cross-Modal Retrieval: A Systematic\nReviewofMethodsandFutureDirections.ArXiv./abs/2308.14263\nLi, S., Shang, H., Wei, D., Guo, J., Li, Z., He, X., Zhang, M., & Yang, H. (2024). LA-RAG:Enhancing\nLLM-basedASRAccuracywithRetrieval-AugmentedGeneration.ArXiv./abs/2409.08597\nLi, S., Park, S., Lee, I., & Bastani, O. (2023). TRAQ: Trustworthy Retrieval Augmented Question", "metadata": {"id": "57e6b25316cdf7d0c22390e9e9641e75740a0eae", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 16, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Li, S., Park, S., Lee, I., & Bastani, O. (2023). TRAQ: Trustworthy Retrieval Augmented Question\nAnsweringviaConformalPrediction.ArXiv./abs/2307.04642\nLi, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024). Retrieval Augmented Generation or\nLong-ContextLLMs?AComprehensiveStudyandHybridApproach.ArXiv./abs/2407.16833\nLiu, Z., Wang, H., Niu, Z., Wu, H., Che, W., & Liu, T. (2020). Towards Conversational Recommendation\noverMulti-TypeDialogs.ArXiv./abs/2005.03954\nMallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., & Hajishirzi, H. (2022). When Not to Trust", "metadata": {"id": "2c49a56b679df3454f0f63030b2cba89217fe936", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 16, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Mallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., & Hajishirzi, H. (2022). When Not to Trust\nLanguage Models: Investigating Effectiveness of Parametric and Non-Parametric Memories. ArXiv.\n/abs/2212.10511\nMombaerts, L., Ding, T., Banerjee, A., Felice, F., Taws, J., & Borogovac, T. (2024). Meta Knowledge for\nRetrievalAugmentedLargeLanguageModels.ArXiv./abs/2408.09017\nNguyen, X., Pandit, S., Purushwalkam, S., Xu, A., Chen, H., Ming, Y., Ke, Z., Savarese, S., Xong, C.,&\nJoty,S.(2024).SFR-RAG:TowardsContextuallyFaithfulLLMs.ArXiv./abs/2409.09916", "metadata": {"id": "df57a359fc04005046a8a39232e658f3c377ceaa", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 16, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Joty,S.(2024).SFR-RAG:TowardsContextuallyFaithfulLLMs.ArXiv./abs/2409.09916\nNiu, C., Wu, Y., Zhu, J., Xu, S., Shum, K., Zhong, R., Song, J., & Zhang, T. (2023). RAGTruth: A\nHallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models. ArXiv.\n/abs/2401.00396\nQian, H., Zhang, P., Liu, Z., Mao, K., & Dou, Z. (2024). MemoRAG: Moving towards Next-Gen RAG Via\nMemory-InspiredKnowledgeDiscovery.ArXiv./abs/2409.05591\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are\nunsupervisedmultitasklearners.OpenAIBlog,1(8),9.", "metadata": {"id": "b2af96b79949dffc2ce40668093de03932081257", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 16, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "unsupervisedmultitasklearners.OpenAIBlog,1(8),9.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S.,Matena,M.,Zhou,Y.,Li,W.,&Liu,P.J.(2019).\nExploringtheLimitsofTransferLearningwithaUnifiedText-to-TextTransformer.ArXiv./abs/1910.10683\nRanade, P., & Joshi, A. (2023). FABULA: Intelligence Report Generation Using Retrieval-Augmented\nNarrativeConstruction.ArXiv.https://doi.org/10.1145/3625007.3627505\nRanjan, R., Gupta, S., & Singh, S. N. (2024). A Comprehensive Survey of Bias in LLMs: Current\nLandscapeandFutureDirections.ArXiv./abs/2409.16430", "metadata": {"id": "c5dcb74002e07d4ec03090cf8276a41740647a2e", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 16, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "LandscapeandFutureDirections.ArXiv./abs/2409.16430\nRavuru, C., Sakhinana, S. S., & Runkana, V. (2024). Agentic Retrieval-Augmented Generation for Time\nSeriesAnalysis.ArXiv./abs/2408.14484", "metadata": {"id": "b630cca974167966682134ef171f5c24a550e6d4", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 16, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Robertson, S.G., & Zaragoza,H., (2009). The Probabilistic Relevance Framework: BM25 and Beyond,\nFoundationsandTrendsinInformationRetrieval,3(4),pp.333-389.\nRoller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott, M., Shuster, K., Smith, E.M.,\nBoureau,Y.,&Weston,J.(2020).Recipesforbuildinganopen-domainchatbot.ArXiv./abs/2004.13637\nSalton, G., Wong, A., & Yang, C. S. (1975). A vector space model for automatic indexing.\nCommunicationsoftheACM,18(11),613-620.\nSanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller,", "metadata": {"id": "713a29cd950339515685711cf1a73b789d6d623d", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 17, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "faster,cheaperandlighter.ArXiv./abs/1910.01108\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., & Manning, C. D. (2024). RAPTOR: Recursive\nAbstractiveProcessingforTree-OrganizedRetrieval.ArXiv./abs/2401.18059\nShi, W., Min, S., Yasunaga, M., Seo, M., James, R., Lewis, M., Zettlemoyer, L., & Yih, W.-T. (2023).\nREPLUG:Retrieval-augmentedblack-boxlanguagemodels.arXivpreprintarXiv:2301.12652.\nShrestha, R., Zou, Y., Chen, Q., Li, Z., Xie, Y., & Deng, S. (2024). FairRAG: Fair Human Generationvia\nFairRetrievalAugmentation.ArXiv./abs/2403.19964", "metadata": {"id": "0f3e7521dbb914d3b682105dff679e891ab09782", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 17, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "FairRetrievalAugmentation.ArXiv./abs/2403.19964\nSutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In\nAdvancesinNeuralInformationProcessingSystems(pp.3104-3112).\nThakur, N., Bonifacio, L., Zhang, X., Ogundepo, O., Kamalloo, E., Li, X., Liu, Q., Chen, B.,\nRezagholizadeh, M., & Lin,J.(2023).NoMIRACL:KnowingWhenYouDon'tKnowforRobustMultilingual\nRetrieval-AugmentedGeneration.ArXiv./abs/2312.11361\nThakur, N., Reimers, N., Ruckl'e, A., Srivastava, A., & Gurevych, I. (2021). BEIR: A Heterogenous", "metadata": {"id": "f474c43ced2c307682a24457deff6190d6f1cc7f", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 17, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Thakur, N., Reimers, N., Ruckl'e, A., Srivastava, A., & Gurevych, I. (2021). BEIR: A Heterogenous\nBenchmarkforZero-shotEvaluationofInformationRetrievalModels.ArXiv,abs/2104.08663.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser,Ł.,&Polosukhin,I.\n(2017).Attentionisallyouneed.InAdvancesinNeuralInformationProcessingSystems(pp.5998-6008).\nWang, X., Wang, Z., Gao, X., Zhang, F., Wu, Y., Xu, Z., Shi,T.,Wang,Z.,Li,S.,Qian,Q.,Yin,R.,Lv,C.,\nZheng, X., & Huang, X. (2024). Searching for Best Practices in Retrieval-Augmented Generation. ArXiv.\n/abs/2407.01219", "metadata": {"id": "cb80f739162f2f98926d99550e6083083461368f", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 17, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "/abs/2407.01219\nWang, Z., Araki, J., Jiang, Z., Parvez, M. R., & Neubig, G. (2023). Learning to Filter Context for\nRetrieval-AugmentedGeneration.ArXiv./abs/2311.08377\nXia, P., Zhu,K.,Li,H.,Zhu,H.,Li,Y.,Li,G.,Zhang,L.,&Yao,H.(2024).RULE:ReliableMultimodalRAG\nforFactualityinMedicalVisionLanguageModels.ArXiv./abs/2407.05131\nXie, S., Sun, C., Huang, J., Tu, Z., & Murphy, K. (2017). Rethinking Spatiotemporal Feature Learning:\nSpeed-AccuracyTrade-offsinVideoClassification.ArXiv./abs/1712.04851", "metadata": {"id": "9a6bacf1ed2d1136c11334564c2f50186db99700", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 17, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Speed-AccuracyTrade-offsinVideoClassification.ArXiv./abs/1712.04851\nXiong, L., Xiong, C., Li, Y., Tang, K., Liu, J., Bennett, P., Ahmed, J., & Overwijk, A. (2020). Approximate\nNearestNeighborNegativeContrastiveLearningforDenseTextRetrieval.ArXiv./abs/2007.00808", "metadata": {"id": "97938be2aa96722d82c00246a8e3cf37bb74bf8a", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 17, "created_at": "2025-09-08T12:16:48Z"}}
{"content": "Yasunaga, M., Aghajanyan, A., Shi, W., James, R., Leskovec, J., Liang, P., Lewis,M.,Zettlemoyer,L.,&\nYih,W.(2022).Retrieval-AugmentedMultimodalLanguageModeling.ArXiv./abs/2211.12561\nZhang, T., Patil, S. G., Jain, N., Shen, S., Zaharia, M., Stoica, I., & Gonzalez, J. E. (2024). RAFT:\nAdaptingLanguageModeltoDomainSpecificRAG.ArXiv./abs/2403.10131\nZhu, Y., Ren, C., Xie, S., Liu, S., Ji, H., Wang, Z., Sun, T., He, L., Li, Z., Zhu, X., & Pan, C. (2024).\nREALM: RAG-Driven Enhancement of Multimodal Electronic Health Records Analysis via Large\nLanguageModels.ArXiv./abs/2402.07016", "metadata": {"id": "eb31054197cf83056aa28cc9195ce02be4f494f6", "source": "A_Comprehensive_Survey_of_Retrieval-Augmented_Gene.pdf", "page": 18, "created_at": "2025-09-08T12:16:48Z"}}
