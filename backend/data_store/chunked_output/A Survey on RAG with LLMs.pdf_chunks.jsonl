{"content": "Available online at www.sciencedirect.com\nAvailable o(cid:94)n(cid:272)lin(cid:349)(cid:286)e a(cid:374)t (cid:272)w(cid:286)ww(cid:24).s(cid:349)c(cid:396)ie(cid:286)n(cid:272)ce(cid:410)direct.com\nAvailable online at www.sciencedirect.com\n(cid:94)(cid:272)(cid:349)(cid:286)(cid:374)(cid:272)(cid:286)(cid:24)(cid:349)(cid:396)(cid:286)(cid:272)(cid:410)\nProcedia Computer Science 00 (2024) 000–000", "metadata": {"id": "7de25496cd441a7b75d9c0ef3cd9f2aeda076875", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Procedia Computer Science 00 (2024) 000–000\nwww.elsevier.com/locate/procedia\nScienceDirect\nProcedia Computer Science 00 (2024) 000–000\nwww.elsevier.com/locate/procedia\nProcedia Computer Science 246 (2024) 3781–3790\n28th International Conference on Knowledge-Based and Intelligent Information & Engineering\nSystems (KES 2024)", "metadata": {"id": "0fb41bc0dd00ff29ae83cc78d2d29b41d2c1f1e2", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Systems (KES 2024)\n28th International Conference on Knowledge-Based and Intelligent Information & Engineering\nSystems (KES 2024)\nA Survey on RAG with LLMs\nA Survey on RAG with LLMs\nMuhammad Arslana*, Hussam Ghanema, Saba Munawarb and Christophe Cruza\nMuhammad ArslaaLanbao*ra,t oHireu Instseradmisci pGlinhaiaren Ceamrnoat, d eS Baoburag oMgneu (InCaB)w, Daijrobn , aFnradnc eC hristophe Cruza", "metadata": {"id": "55040f255526fa111314dd9701d2c8effad356cd", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "bNational University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan\naLaboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Dijon, France\nbNational University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan\nAbstract\nAInb tshter afacst t-paced realm of digital transformation, businesses are increasingly pressured to innovate and boost efficiency to remain", "metadata": {"id": "6fe14f9392605d147bf85d256e5002b970251302", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "competitive and foster growth. Large Language Models (LLMs) have emerged as game-changers across industries,\nIrnev tohleu tfiaosnt-ipziancge dv raerailomus o fs edcigtoitrasl tbrya nshfaorrnmesastiinogn , ebxutseinnseisvsee s taerxet indcarteaa stion galnya plyrezses uarnedd tgoe innenroavtea teh uamnda nb-oloikset etfefixcti.e nDceys ptoit ere mthaeiinr", "metadata": {"id": "73aaec07b4f61ea78426f5305e2b68cb9465881f", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "cimomprpeestsiitvivee caapnadb ilfiotisetse,r LgLrMows tho.f teLna regnec ouLnatnegr ucahgael leMngoedse lws he(Ln LdMeasl)i ngh awveit he mdoemrgaeidn -sapse cigfaicm qeu-cehriaensg, eprso teanctrioalslsy lienadduisntgri etso,", "metadata": {"id": "c72badf476379f7e62a58f3f929ce7116f56471e", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "rinevacocluutriaocnieizsi nign vthaeriior uosu tspeucttso.r sI nb yr eshpaornnesess, inRge treixetveanls-iAvue gtmexetn tedda taG eton earantaiolynz e( RaAndG )g ehnaesr aetme ehrguemda na-sl ikae vtieaxbtl.e Dsoelsuptiitoen .t hBeiyr", "metadata": {"id": "45ac1a0077bfef5cc3570f8031b85e08b6a66173", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "ismeapmrelesssisvlye icnatpegabrailtiitniges e, xLteLrMnasl doafttae nr eetrniecvoauln itnerto c theaxltl egnegneesr awtiohnen p rdoecaelsinsegs ,w RiAthG d oaimmasi nto-s epnehciafnicc eq tuheer iaecsc, upraocteyn atinadll yre lleevadanincge otof", "metadata": {"id": "b9ab497fafd5e658f2867f4779378f0e36c33d9a", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "itnhaec gceunraecraietesd inco nthteenirt . oHuotpwuetsv.e rI,n e xriesstpinogn sleit,e rRateutrriee vreavl-iAewusg mteenndt etdo fGoceunse rpartiiomna r(ilRyA oGn )t hhea ste cehmneorlgoegdic aals ada vvaniacbelme esnotlsu otifo nR.A BGy,", "metadata": {"id": "001be1a02391055ded9a3ef9a2f3c49e3792557e", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "soevaemrlloeosksliyn gi nat ecgormatpinregh eexntseirvnea el xdpaltoar raetitorine voafl iitns taop tpelxict agtieonnesr.a tTiohnis ppraopceers sseese,k Rs AtoG a dadimress st oth eins hgaanpc eb yth per oavcciduirnagc ya athnodr oreulgehv arnecveie owf", "metadata": {"id": "c9ee31b344ccf8b9bf94c8508c773d6533c97abc", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "tohfe R gAenGe raaptepdli ccaotniotenns,t . eHncoowmepvaesr,s ienxgi sbtiontgh ltiatsekra-stupreec irfeicv iaenwds dteisncdi ptloin feo-csupse cpirfiimc satruildyi eosn, wthhei ltee cahlsnoo loougtilcinali nagd vpaontecnetmiaeln atvs eonfu ResA fGor,", "metadata": {"id": "c39805159732294d99e309242bf736a95e03c6c3", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "ofuvteurrleo oreksineagr cah c.o Bmyp rsehheedndsiinvge leigxhptl oornat icounr roefn ti tsR aApGpl irceasteiaorncsh. Tanhdis opuatplienri nsege kfust utor ea dddirreecstsi othniss, gthaips breyv pierwov iadiminsg tao thcaotraoluygzhe rfeuvrtiheewr", "metadata": {"id": "9049d62bfc07df40845875cc3cfe4919c99f119a", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "oexf pRloArGat iaopnp alnicda tdioevnesl, oepnmcoemntp ians tshinisg dbyontahm taics kf-iesplde,c tihfiecr eabnyd cdoinsctriipbluintien-gsp teoc oifnicg ositnugd ideisg, iwtahl itlrea naslfsoor mouattliionnin egf fpoorttse.n tial avenues for", "metadata": {"id": "0b1d7c3aa9f6c65d6f616d353e3f0248efd2e6f7", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "f©u t2u0re2 4r eTsehaer Achu. thBoyr ss.h Peudbdliinsgh eldig bhyt oEnL ScuErVreInEtR R BA.GV .r esearch and outlining future directions, this review aims to catalyze further", "metadata": {"id": "e0f362355d57826d36202eb3f48677cf971e8a41", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "eT© xh pi2sl 0 o i2 rsa 4 at i Tno h noe pa Aennd u tad hce ocv res es. ls o P ap urm btil eci nlseh t euin dn dt b hey irs E tdhl y see nCv a iCm er iB c B Yf . i V-eN. ldC, -tNheDre lbiyce cnosnet r(ihbtutptisn:/g/c troe aotnivgeocinogm dmigointas.lo trrga/nlsicfoenrmseast/iboyn- nefcf-onrdts/4. .0)", "metadata": {"id": "d92d078c23b860e6d08b7d1d83c94880f84a929f", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)\n©Pe e2r0-2re4v Tiehwe Aunudthero rrse.s pPounbsliisbhileidty b oyf EthLeS sEcVieInEtiRfi cB c.Vom. mittee of KES International\nPeer-review under responsibility of the scientific committee of the 28th International Conference on Knowledge Based and", "metadata": {"id": "cf36ea68562556fd83bfe3b8898ac8a07a2d602d", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "TKehyiws oisr dasn: Loapregne aLcacnegsusa gaer tMicoled eulns d(LerL Mthse) ;C NCa tBurYal- LNaCng-NuaDge l Picreoncesses i(nhgt t(pNsL:/P/c)r; eRaetitrvieevcaolm-Amugomnse.notregd/ Glicenenersaetsio/bn y(R-nAcG-n)d; /T4e.x0t) generation;\nIntelligent information and Engineering Systems\nPDeigeirt-arle tvraineswfo urmndateior nr.e sponsibility of the scientific committee of KES International", "metadata": {"id": "40d915eefdd1d094f4fe9a90fc72ca6fe1ef6feb", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Keywords: Large Language Models (LLMs); Natural Language Processing (NLP); Retrieval-Augmented Generation (RAG); Text generation;\nDigital transformation.\n1. Introduction\n1. IDnitgriotadlu ctrtaionnsf ormation signifies the incorporation of digital technology across different facets of a business,", "metadata": {"id": "20a6ce8cb557bc3a4938b80e8266e54b14e2c3ca", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "reshaping its operations and value delivery to customers [1]. At the forefront of driving such transformative\npraDctiigcietsa la rtrea nLsafrogrem Latainognu saiggen iMfieosd ethlse (iLnLcoMrps)o,r aatdiovnan ocef dd migaitcahl inteec hlenaorlnoignyg macorodsesl s dtirfafienreedn t efxatceentssi voefl ya obnu tseixnteusasl,", "metadata": {"id": "8c1bdab6e7e7e4a52ef77688a348d47aaa57f4fe", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "rdeastha atpoi ncgo mitpsr eohpeenrda tainodn sp raonddu cvea hluuem danel-ilvikeery t etxot [c1u]s. tLoLmMerss, s[u1c].h Aast ththee G feonreerfarotinvte oPfr ed-trriaviinnign gs uTcrhan strfaonrmsfoerr m(GatPivTe)\npractices are Large Language Models (LLMs), advanced machine learning models trained extensively on textual", "metadata": {"id": "1e09886460a3713a9717265f5e9ff2882dc2b7bc", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "data to comprehend and produce human-like text [1]. LLMs, such as the Generative Pre-training Transformer (GPT)\n* Corresponding author. Tel.: +33 03 80 39 50 00; fax: +33 03 80 39 50 69.\nE-mail address: muhammad.arslan@u-bourgogne.fr\n* Corresponding author. Tel.: +33 03 80 39 50 00; fax: +33 03 80 39 50 69.", "metadata": {"id": "d5005791cba24588e2298de425ba31132e32d5a3", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "* Corresponding author. Tel.: +33 03 80 39 50 00; fax: +33 03 80 39 50 69.\n1877E--0m5a0i9l a©d d2r0e2s4s: T mhue hAaumthmoards.. aPrsulbalnis@heud-b boyu rEgLoSgEneV.fIrE R B.V.\nThis is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)\nPeer-review under responsibility of the scientific committee of KES International", "metadata": {"id": "ceec119730746ce4c5030b2316a30d50bf1ba7c3", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Peer-review under responsibility of the scientific committee of KES International\n1877-0509 © 2024 The Authors. Published by ELSEVIER B.V.\nThis is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)\n1877-0509 © 2024 The Authors. Published by Elsevier B.V.\nPeer-review under responsibility of the scientific committee of KES International", "metadata": {"id": "36752bd5719521fb36b0c3364fb983ee45d8bca3", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Peer-review under responsibility of the scientific committee of KES International\nThis is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)\nPeer-review under responsibility of the scientific committee of the 28th International Conference on Knowledge\nBased and Intelligent information and Engineering Systems\n10.1016/j.procs.2024.09.178", "metadata": {"id": "b73dbcfcbbbd8278454b0f96055f8b29bd404c21", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Based and Intelligent information and Engineering Systems\n10.1016/j.procs.2024.09.178\n10.1016/j.procs.2024.09.178 1877-0509", "metadata": {"id": "b2c58916b7c8448344c73acc3254f35e25abe253", "source": "A Survey on RAG with LLMs.pdf", "page": 1, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "3782 Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790\n2 Arslan et al. / Procedia Computer Science 00 (2024) 000–000\nseries [2, 3] and others, have demonstrated remarkable capabilities in NLP tasks [4]. However, these models face\nchallenges when dealing with domain-specific queries, often generating inaccurate or irrelevant information,", "metadata": {"id": "1857b95c4892054481d868fcaae074f18829b976", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "commonly referred to as “hallucinations”, particularly when data is sparse [5]. This limitation makes deploying\nLLMs in real-world settings impractical, as the generated output may not be reliable [4].\nIn the middle of 2020, Lewis et al. [6] introduced RAG, a significant advancement in the field of LLMs for", "metadata": {"id": "aaf5e8f86a5d5259ded60ce439d366f35327fcf5", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "improving generative tasks (see Fig. 1 (a)). RAG incorporates an initial step where LLMs search an external data\nsource to retrieve relevant information before producing text or answering questions. RAG addresses these\nlimitations by integrating external data retrieval into the generative process, thereby enhancing the accuracy and", "metadata": {"id": "64fef01f01934d852e6cd99b9ba510c7057a18bb", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "relevance of the generated output. By dynamically retrieving information from knowledge bases during inference,\nRAG provides a more informed and evidence-based approach to language generation, significantly reducing the risk\nof hallucinations and improving the overall quality of the generated text [4, 6]. This approach has the potential to", "metadata": {"id": "313ffd479987e53aa7a057c1d861ecddd7e8606a", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "make LLMs more practical for real-world applications, as it ensures that the generated output is grounded in\nretrieved evidence, leading to more reliable and accurate results. Fig. 1 (b) showcases how real-time business\nsystems can leverage the RAG with LLM architecture. As an example, without RAG, the system lacks access to", "metadata": {"id": "94d8941eaae8b9818a281dd226d7573281211f29", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "real-time or updated information. However, with RAG integration, leveraging external data sources such as news\narticles, the system can respond to current business events, presenting opportunities for business intelligence\nanalysts.\n(a) (b)\nFig. 1. (a) A generic RAG architecture, where users’ queries, potentially in different modalities (e.g., text, code, image, etc.), are inputted into", "metadata": {"id": "cd7e9c3af8262a73dbd83342f01078ad41915adc", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "both the retriever and the generator. The retriever scans for relevant data sources in storage, while the generator engages with the retrieval\noutcomes, ultimately generating results across various modalities [6]; Fig. 1. (b) illustrates how RAG integration with the LLM handles queries\nthat fall outside the scope of the LLM’s training data.", "metadata": {"id": "92244607095cfcc1cc3e11a4bd29fa20d5b641d3", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "that fall outside the scope of the LLM’s training data.\nWhile the field of RAG has seen substantial growth, several online surveys [4, 7, 8, 9] have explored\ntechnological advancements in RAG. Although these surveys provide valuable insights and references, they offer\nonly a limited overview of RAG applications. To address this gap, this paper aims to provide an exhaustive", "metadata": {"id": "6f39807e4289e2e94c79148fbdaa7a1f0ad09fa2", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "overview of RAG applications, including both task-specific and discipline-specific studies, as well as future\ndirections. By highlighting the current state of RAG research and its potential future directions, this review aims to\ninspire further investigation and development in this exciting field.", "metadata": {"id": "bac492b603895aee7f52e465c412d98cfe9b96de", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "inspire further investigation and development in this exciting field.\nThe paper’s structure is as follows: Section 2 presents the adopted research methodology for this survey. In\nSection 3, we provide an overview of RAG applications, followed by a detailed discussion in Section 4. The paper\nconcludes in Section 5, summarizing the key findings and implications of the study.\n2. Background", "metadata": {"id": "9652e2411288218193d688176bb596f2767eee3c", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "concludes in Section 5, summarizing the key findings and implications of the study.\n2. Background\nThe research method (see Fig. 2) employed in this paper involves a thorough review and analysis of research\npublications related to RAG. The main objective is to identify and categorize its applications across various NLP", "metadata": {"id": "f7542d13d31b91f9f727ca68f6132e3e03a876b6", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "tasks and disciplines. The paper begins by collecting research publications specific to RAG, focusing on their\napplications. Since the RAG with LLM domain is relatively new and emerging, with many studies available as pre-", "metadata": {"id": "ca721619b57825704a0fa561ed3e515207b1aebd", "source": "A Survey on RAG with LLMs.pdf", "page": 2, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790 3783\nArslan et al. / Procedia Computer Science 00 (2024) 000–000 3\nprints online, limiting the search to platforms such as Scopus or IEEE would greatly reduce the number of studies.\nTherefore, Google Scholar was utilized to access the studies on RAG. However, in cases where both pre-print and", "metadata": {"id": "cede55a33d599a0676c6b2eb0bf8b591557282fe", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "published versions of a study were available, the published version was chosen to cover the maximum number of\npeer-reviewed studies. Each study underwent manual review to assess its comprehensiveness and depth, excluding\nshort studies. It is important to note that the purpose of the survey is not to cover the most optimal studies, but rather", "metadata": {"id": "9c9b7db1f3f70dfe0dc973ca6372680d75f6e6ae", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "to provide an overview of how this field has attained significant attention in a short period, with researchers\nexploring diverse application scenarios.\nThe keywords used to collect research publications included “retrieval augmented generation”, “RAG\napplications”, “generative models with retrieval”, “external data retrieval in text generation”, “enhancing text", "metadata": {"id": "30777c8f247bf1e53399295635d1c9bda39af4e9", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "generation with retrieval”, “integrating retrieval into generative models”, “external knowledge in text generation”,\n“retrieval-based text generation”, “information retrieval for text generation”, and “contextualized retrieval in\nlanguage models”. These publications are then classified into two principal categories: task-based classification and", "metadata": {"id": "575b543e0efb75757609f6deea11ff8063572309", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "discipline-based classification. Task-based classification focuses on categorizing RAG studies according to their\nexecution of information processing tasks, particularly within NLP. Conversely, discipline-based classification\ncategorizes studies based on their application to specific domains. Under the task-based classification, the", "metadata": {"id": "9328da4cdf02b1b7a737cd4a7be3299c7c1608c1", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "publications are further subdivided into categories such as Question Answering (QA), Text Generation and\nSummarization, Information Retrieval and Extraction, Text Analysis and Processing, Software Development and\nMaintenance (SDM), Decision Making and Applications, and Other Categories. Similarly, under the discipline-", "metadata": {"id": "74cb6758e5da933a003c79ac23c407ee7421e699", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "based classification, the publications are further subdivided into categories such as Medical/Biomedical, Financial,\nEducational, Technology and Software Development, Social and Communication, Literature, and Other Categories.\nThese categories are selected based on an understanding of the context of the studies and the underlying problems", "metadata": {"id": "8f5321916632ab9602560f3ff3df9d0e199db642", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "they address. Within both classification methods, “software development” stands out as a common category. It\ninvolves programming information processing tasks under task-based classification and encompasses systems for\ndeveloping various applications across different domains under discipline-based classification. Figure 3 illustrates", "metadata": {"id": "0c0025cecb613067ec8ddefcc86147f58b41a859", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "the number of publications related to RAG applications from 2020 to February 2024. Specifically, there was a single\npublication found in 2020, 6 publications in 2022, 28 publications in 2023, and 16 publications until February 2024,\nindicating a growing interest and research activity in the field of RAG applications.\nFig. 2. Research Method", "metadata": {"id": "035175dc1f96348b81537b0ec05a8d76ea047291", "source": "A Survey on RAG with LLMs.pdf", "page": 3, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "3784 Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790\n4 Arslan et al. / Procedia Computer Science 00 (2024) 000–000\nFig. 3. Evolution of Research Publications on RAG Applications\n3. Applications of RAG with LLMs\nUpon thorough examination of the selected papers focusing on RAG applications, we uncovered a vast array of", "metadata": {"id": "76ec4390c5ac0cbb40039645abc677f51c810e89", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "diverse applications. These findings are distilled into a comprehensive table format (see Table 1), detailing three\ncrucial aspects: 1) Use case with RAG, 2) Used datasets/benchmarks, and 3) Application area. Noteworthy\napplications span various domains, including biomedical, financial, and medical inquiries, alongside text", "metadata": {"id": "875cd1c859d2924be6ba3897f6da0a67b02feaa6", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "summarization and book review generation. RAG’s versatility extends to commonsense QA, table-based queries,\nand clinical decision-making, among others. It further encompasses educational decision making, textbook question\nanswering, and enterprise search functionalities. RAG is instrumental in sentiments classification, health education,", "metadata": {"id": "9e83d72f72fa4d93be5adde99c4b94dab1c2cfa6", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "and generating biomedical explanations, while also enhancing user writing accuracy and speed. Its utility spans\nhumanitarian assistance, generating informative dialogues, crafting realistic images and intricate plotlines, and much\nmore.\nAdditionally, RAG aids in natural language QA, disease identification, and information extraction. It handles", "metadata": {"id": "98adf72df69659b528221adeb711ab6ff0126e3c", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "decision-making tasks, hashtag management, hate speech detection, and scientific document classification. RAG\nexcels in entity description generation, text correction, and SQL translation, while also enhancing open-domain QA\nand professional knowledge inquiries. Also, it extends the capabilities of machine translation tasks beyond text-to-", "metadata": {"id": "96fd769080f82ac943adf95889225cae2a874cae", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "SQL, such as neural text re-ranking [6]. Moreover, it supports multicultural enterprise queries, e-commerce\nsearches, and personalized dialogue systems. Furthermore, RAG facilitates event argument extraction, intelligence\nreport generation, short-form QA, automated transactions, and private data handling. Lastly, it contributes to science", "metadata": {"id": "8f5e0f72d5201a685a7a13c05cf13fad64ac7676", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "QA, clinical writing, and pharmaceutical regulatory compliance inquiries.\nAfter compiling all the applications of RAG, the subsequent step involves categorizing them based on the\nspecific nature of the NLP tasks they tackle (see Table 2 and Fig. 4). From the compiled publications, it was", "metadata": {"id": "6e43b602bb26c8aef0cb8e93e87705ceeeae02b7", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "observed that 20 studies were dedicated to QA, 6 to Text Generation and Summarization, 6 to Information Retrieval\nand Extraction, 5 to Text Analysis and Processing, 4 to SDM, and 5 to Decision Making and Applications, while the\nremaining 6 studies were classified under \"Other Categories.\" This classification is significant as it helps in", "metadata": {"id": "4f8955af965d1499154bf65255cd424d96a2ab87", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "understanding the distribution and focus of RAG applications across different NLP tasks. Additionally, since RAG\napplications span various disciplines, further classification (see Table 3 and Fig. 5) reveals that 9 publications were\nrelated to Medical/Biomedical, 2 to Financial, 2 to Educational, 9 to Technology and Software Development, 7 to", "metadata": {"id": "826d4e4ac0c3925a6e74657b287b6fd34452ddad", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Social and Communication, and 3 to Literature, with the remaining falling into \"Other Categories\".\nTable 1. Applications of RAG\nNo. Use case with RAG Used datasets / benchmarks Application area\n1 MIRAGE: Medical information RAG [10] Medical QA datasets Biomedical QA\n2 RAG for improved context accuracy [11] Financial reports Financial QA", "metadata": {"id": "e44467934eaf5bdfdb014d753c3ef468314105d4", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "2 RAG for improved context accuracy [11] Financial reports Financial QA\n3 Retrieval-augmented Electrocardiography (ECG) [12] Cardiac symptoms and sleep apnea diagnosis Medical QA\n4 Representative Vector Summarization (RVS) [13] PDFs, text documents, spreadsheets, etc. Medical text summarization\n5 Retrieval-augmented controllable reviews [14] Amazon book reviews Book review generation", "metadata": {"id": "a96e54ad8f65bda28375d652282a1333ea96f593", "source": "A Survey on RAG with LLMs.pdf", "page": 4, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790 3785\nArslan et al. / Procedia Computer Science 00 (2024) 000–000 5\n6 Retrieval-augmented knowledge graph reasoning [15] Commonsense QA and OpenBookQA. Commonsense QA\n7 Answers from table corpus via RAG [16] Wikipedia data Table QA\n8 LiVersa: a liver disease specific LLM using RAG [17] Liver Diseases Medical QA", "metadata": {"id": "7ce8fbe89afbba7080cbdbad243aa8ffb29a63b5", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "8 LiVersa: a liver disease specific LLM using RAG [17] Liver Diseases Medical QA\n9 Almanac: RAG for clinical medicine [18] Guidelines and treatment recommendations. Clinical decision-making\n10 Assessment of tutoring practices [19] Dialogue transcripts from a middle-school. Educational decision making\n11 Handling out of domain scenarios [20] Life science, earth science, etc. lessons. Textbook QA", "metadata": {"id": "03ea9fd2d5c3dda37e1318509484091b04a1865c", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "11 Handling out of domain scenarios [20] Life science, earth science, etc. lessons. Textbook QA\n12 Automated form filling [21] Request forms for IT projects Enterprise search\n13 Financial sentiment analysis [22] Twitter financial news and FiQA datasets Sentiments classification\n14 Frontline health worker capacity building [23] Pregnancy-related guidelines Health education QA", "metadata": {"id": "f786eaef2d0f24d7fb237a50a9af20e650086403", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "14 Frontline health worker capacity building [23] Pregnancy-related guidelines Health education QA\n15 Self-BioRAG: a framework for biomedical text [24] Biomedical instruction sets Biomedical Informatics\n16 Hybrid RAG for real-time composition assistance [25] WikiText-103, Enron Emails, etc. Writing speed and accuracy", "metadata": {"id": "24ff2d839737f7688930f6d3425754aed4ae63fa", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "17 RAG-Fusion to obtain product information [26] Product datasheets Technical information QA\n18 Commit message generation for code intelligence [27] MCMD dataset SDM\n19 FloodBrain: Flood disaster reporting [28] ReliefWeb reports Humanitarian assistance\n20 Rich answer encoding [29] MSMARCO QA and WoW dataset. Generative QA", "metadata": {"id": "a9232a188c32f493f160a7a9fe851b7ccfe9a407", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "20 Rich answer encoding [29] MSMARCO QA and WoW dataset. Generative QA\n21 Text-to-image generator [30] COCO and WikiImages datasets. Realistic images generation\n22 Code completion framework [31] CodeXGLUE and CodeNet datasets. SDM\n23 Complex story generation framework [32] IMDB movie details dataset Generate stories", "metadata": {"id": "cd9ffed3f5032ae937a40b07ae534afeb4a978bd", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "23 Complex story generation framework [32] IMDB movie details dataset Generate stories\n24 TRAC: Trustworthy retrieval augmented chatbot [33] Natural Question dataset Natural QA\n25 Clinfo.ai using scientific literature [34] PubMed dataset Medical QA\n26 RealGen for controllable traffic scenarios [35] nuScenes dataset Critical traffic scenarios", "metadata": {"id": "b0399ae7e9936333ed239062c22f3b954744aa41", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "26 RealGen for controllable traffic scenarios [35] nuScenes dataset Critical traffic scenarios\n27 Zero-shot disease phenotyping [36] Clinical notes Identifying diseases\n28 RAP-Gen for automatic program repair [37] TFix, Defects4J, etc. datasets SDM\n29 Code4UIE : retrieval-augmented code generation [38] ACE04, ACE05, CoNLL03, etc. datasets Information extraction", "metadata": {"id": "a32c2abe4fc6bae01b8e11ca27634a953fc8b714", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "30 RAP: retrieval-augmented planning [39] ALFWorld, Webshop, etc. datasets Decision-making\n31 RIGHT for mainstream hashtag recommendation [40] Twitter and Weibo data. Retrieval-enhanced hashtags\n32 RAUCG for counter narrative generation for hate speech MultitargetCONAN dataset Combating hate speech\n[41]", "metadata": {"id": "a05bd7b0134731b384fa21f3186f66fd5cbf719b", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "[41]\n33 Weakly-supervised scientific document classification AGNews and MeSH datasets. Scientific documents\n[42] classification\n34 rT5 for Chinese entity description generation [43] XunZi and MengZi datasets. Entity description generation\n35 RSpell: domain adaptive Chinese spelling check [44] CSC dataset Text error correction", "metadata": {"id": "9e58d1920dbf6404e90bf78662a6485369b9449b", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "35 RSpell: domain adaptive Chinese spelling check [44] CSC dataset Text error correction\n36 XRICL: cross-lingual retrieval-augmented in-context XSPIDER and XKAGGLE-DBQA datasets. Text-to-SQL translation\nlearning for cross-lingual text-to-SQL semantic parsing\n[45]\n37 SELF-RAG: learning to retrieve, generate, and Open-Instruct processed data. Open-domain QA and fact", "metadata": {"id": "47ad44665d4353b06f523813dcf0a5d54bc0afc2", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "critique through self-reflection [46] verification\n38 ChatDOC with enhanced PDF structure recognition [47] Academic papers, financial reports, Professional knowledge QA\ntextbooks, and legislative materials\n39 G-Retriever for textual graph understanding [48] GraphQA (ExplaGraphs, SceneGraphs and Chat with graphs\nWebQSP)", "metadata": {"id": "2cfef734cda65df8968c38e6db355efaee002a64", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "WebQSP)\n40 Enhancing multilingual information retrieval in HR standard operating procedures and Multicultural enterprise QA\nmixed Human Resources (HR) environments [49] Quality Assurance (QA) documents\n41 Differentiable RAG [50] User-clicked logs E-commerce search (query\nintent classification)\n42 RAG to elevate low-code developer skills [51] Caspio and Power automate data SDM", "metadata": {"id": "2fdf5f5bb3608053e900fb8ea3b4907e589ec870", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "42 RAG to elevate low-code developer skills [51] Caspio and Power automate data SDM\n43 UniMS-RAG: a unified multi-source RAG [52] DuLeMon and KBP datasets Personalized dialogue\nsystems\n44 RAG QA for event argument extraction [53] ACE 2005 and WikiEvent datasets Event argument (answer)\nextraction\n45 FABULA: retrieval-augmented narrative construction OntoNotes and Pile datasets Intelligence report", "metadata": {"id": "c7e8376df513c274d159c9dd8f7d99031ce48830", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "[54] generation\n46 Time-Aware Adaptive Retrieval (TA-ARE) [55] RetrievalQA dataset Short-form open-domain\nQA\n47 Cash transaction booking via RAG [56] Cash Management Software (CMS) Automated cash transaction\ntransactions. booking\n48 Retrieval-Augmented Thought Process (RATP) [57] Boolq and emrQA datasets. QA with private data", "metadata": {"id": "29a3969e85b6bb469d64e361f9427161c30c8166", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "48 Retrieval-Augmented Thought Process (RATP) [57] Boolq and emrQA datasets. QA with private data\n49 ATLANTIC for interdisciplinary science [58] S2ORC dataset Science QA and scientific\ndocument classification\n50 Writing documents for clinical trials [59] FDA guidance database, ClinicalTrials.gov, Clinical-related writing\nand AACT database.", "metadata": {"id": "8be72ccdd5c8c3aabe8c0faeb7829bc699787550", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "and AACT database.\n51 QA RAG model [60] FDA Q&A datasets Pharma industry regulatory\ncompliance QA", "metadata": {"id": "9fc00c96cb107119f8f06b922aec60b88a003e7e", "source": "A Survey on RAG with LLMs.pdf", "page": 5, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "3786 Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790\n6 Arslan et al. / Procedia Computer Science 00 (2024) 000–000\n4. Discussion\nThe classification of RAG applications according to the specific NLP tasks they target holds significant\nimportance for several reasons. Firstly, it offers valuable insights into the distribution and focus of RAG applications", "metadata": {"id": "cc5b51de076072caee20b13d0497bb6aaa0161d1", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "across various tasks within the field of NLP. By quantifying the number of studies dedicated to each task,\nresearchers gain a deeper understanding of where efforts and resources are predominantly concentrated within the\nRAG domain. By analyzing the distribution of RAG applications, researchers can discern prevailing trends in", "metadata": {"id": "511e12f664cc3cdb36d76b989b58c464a0b56164", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "research interest and identify emerging areas of importance. The classification of RAG applications based on\ndiscipline offers valuable insights into its widespread adoption across various domains. This classification not only\nprovides a comprehensive understanding of RAG’s applicability but also underscores its potential to revolutionize", "metadata": {"id": "47c8ee6d2d367ae395ab4a341ab0776361089d40", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "various domains, thereby contributing significantly to the advancement of NLP technologies.\nWhile this survey offers a comprehensive overview of RAG applications across various NLP tasks and\ndisciplines, it also has its limitations. 1) Given that RAG technology is still emerging, the majority of RAG-based", "metadata": {"id": "605f9e929df37637a269f5893b29ffc59d83fd96", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "studies are available in pre-print formats on platforms like arXiv, lacking peer review. This raises questions about\ntheir authenticity. 2) Additionally, the survey overlooks the technical implementation details and challenges\nassociated with using RAG technology alongside open-source LLMs. Organizations may find RAG implementation", "metadata": {"id": "70f5c3e459f0a43ac79c007cfd2a254f2dc60ab1", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "costly if they do not opt for open-source LLM architectures, especially considering the expense of querying the\nLLM via Application Programming Interface (API). 3) Furthermore, the performance of RAG concerning the\nvolume and variety of datasets has not been discussed. Deploying RAG with large datasets of varying structures", "metadata": {"id": "d394a2c25db203a8d4c2ac160341a50de5bba1c7", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "(e.g., structured, semi-structured, or non-structured) may lead to processing delays, warranting further exploration\nbefore selecting a RAG with LLM integrated solution for organizational deployment.\n4) Additionally, this survey did not cover the diverse range of RAG architectures and technologies available for", "metadata": {"id": "a33bc35419333b56d6534203706920b9f19a4910", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "integration with different LLMs. Future work should delve into these options to discuss how various RAG solutions\ncan be adapted with LLMs for different NLP tasks and applications. 5) Furthermore, the survey did not address the\naccuracy of information obtained from RAG with LLM solutions. It is essential to explore the reliability of these", "metadata": {"id": "793531071b21096c8bdbf16784d2fc9d3e08b36c", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "systems and assess the organizations’ dependency on their generated responses. LLMs often generate responses with\nhigh confidence, making it challenging to evaluate the accuracy of the information provided. 6) While the survey\nprimarily focuses on task-based and discipline-based applications of RAG, there is a need for further research to", "metadata": {"id": "61da8005d606cd787aa92885acf849eae352ea63", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "explore ethical considerations associated with its usage, especially when dealing with sensitive datasets. For\nexample, in the biomedical domain, RAG has the potential to accidentally expose private information to analysts,\nraising concerns about data privacy and security. Additionally, in the legal domain, RAG may mistakeably reveal", "metadata": {"id": "be775952e9546ff1a6cbadf7729488fc4f3e45fb", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "privileged information during document analysis, potentially violating client confidentiality and attorney-client\nprivilege. Therefore, future studies should delve deeper into these ethical implications to ensure responsible and\nethical use of RAG technology across various domains.\n5. Conclusion", "metadata": {"id": "fe164654b5568d12c1f478b146ae30cc497d6522", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "ethical use of RAG technology across various domains.\n5. Conclusion\nThis article offers a thorough examination of the applications of RAG with LLMs, showcasing their potential to\ndrive digital transformation across diverse industries. Initially, it gathers the latest publications on RAG from online", "metadata": {"id": "04ffd228c22b9c727896acdf91e67b222daa48ee", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "repositories. These publications are then classified based on task-oriented and discipline-oriented criteria. A notable\ntrend observed is the increasing number of research papers on RAG deposited in open-access sources, particularly\nsince 2023. However, many works remain unpublished or are in the preprint stage, awaiting review by various", "metadata": {"id": "f257c394b0978e5665446ac84f694ef2f943a477", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "journals. A significant portion of these studies primarily focus on the task of QA in NLP. Conversely, there is a\nnoticeable gap in research exploring Entity Linking, an essential NLP task that contributes to knowledge graph\ndevelopment. Addressing this gap could unlock numerous applications in the realm of linked data. Regarding", "metadata": {"id": "7a9c9c34b700cd701ca0b2589dc16f26bd00194b", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "disciplines, the majority of research applications are concentrated in the fields of Medical/Biomedical and\nTechnology and Software Development. In contrast, disciplines such as Business and Agriculture receive\ncomparatively less attention. Future research endeavors should aim to bridge this gap by addressing the specific\nneeds of these underrepresented disciplines.", "metadata": {"id": "2de5ee494e536bfad6a9cea613e185dd52ab7099", "source": "A Survey on RAG with LLMs.pdf", "page": 6, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790 3787\nArslan et al. / Procedia Computer Science 00 (2024) 000–000 7\nTable 2. Task-based classification of RAG applications. The detailed categories are derived from the \"Application area\"\ncolumn of Table 1. These categories are assigned based on a thorough comprehension of the study’s context.", "metadata": {"id": "48de33bcc8a7d86369638352d380f758b63504b4", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "1) Question Answering (QA) 4) Text Analysis and Processing\n- Sentiments classification [13]\n- Biomedical QA [1] - Multicultural enterprise QA [40]\n- Text error correction [35]\n- Financial QA [2] - Open-domain QA and fact verification [46]\n- Text-to-SQL translation [36]\n- Medical QA [3] - Short-form open-domain QA [46]\n- Scientific documents classification [33]", "metadata": {"id": "2f8c08538f7ad16023ba98f749cab2155f54acb6", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Medical QA [3] - Short-form open-domain QA [46]\n- Scientific documents classification [33]\n- Commonsense QA [6] - Generative QA and informative conversations [29]\n- Combating online hate speech [32]\n- Textbook QA [11] - Pharma industry regulatory compliance QA [51]\n- Health education QA [14] - Science QA and document classification [49]\n5) Software Development and", "metadata": {"id": "c1041e24adf9378c0642a5107bb147959e9db808", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "5) Software Development and\n- Technical product information QA [17] - Clinical-related writing [50]\nMaintenance\n- Natural QA [24] - Personalized dialogue systems [43]\n- Code intelligence [18]\n- Professional knowledge QA [38]\n- Code completion [22]\n2) Text Generation and Summarization\n- Automatic program repair [28]\n- Medical text summarization [4]\n- Elevate low-code developer skills [42]", "metadata": {"id": "bfc8438f69d9f181126b7cacfd38dbe410c8456c", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Medical text summarization [4]\n- Elevate low-code developer skills [42]\n- Book review generation [5]\n- Biomedical Informatics [15]\n6) Decision Making and Applications\n- Generate stories with complex plots [23]\n- Clinical decision-making [9]\n- Generate realistic and faithful images [21]\n- Educational decision making [10]\n- Entity description generation [34]\n- Decision-making applications [30]", "metadata": {"id": "43d6457ca78bde190feb63b7d4d0761e118f261e", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Entity description generation [34]\n- Decision-making applications [30]\n- Automated cash transaction booking [47]\n3) Information Retrieval and Extraction\n- Intelligence report generation [45]\n- Table QA [7]\n- Enterprise search [12]\n7) Other Categories:\n- Retrieval-enhanced hashtags [31]\n- Editing and crafting diverse behaviors,", "metadata": {"id": "8023707de68f2bf6ad848844685c68f53703b816", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "7) Other Categories:\n- Retrieval-enhanced hashtags [31]\n- Editing and crafting diverse behaviors,\n- Information extraction [29] including critical traffic scenarios [26]\n- Event argument (answer) extraction [44] - Identifying diseases [27]\n- E-commerce search (query intent classification) [41] - Chat with graphs [39]\nTask: (Count of Publications)\nQuestion Answering (QA): (20)", "metadata": {"id": "7f851b2fd618c097f5be77326dac86323bc6f975", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Task: (Count of Publications)\nQuestion Answering (QA): (20)\nText Generation and Summarization: (6)\nInformation Retrieval and Extraction: (6)\nText Analysis and Processing: (5)\nSoftware Development and Maintenance: (4)\nDecision Making and Applications: (5)\nOther Categories: (6)", "metadata": {"id": "393a43bbd2a518f46dd7e7ac01b6b1dfa79af97d", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Decision Making and Applications: (5)\nOther Categories: (6)\nFig. 4. Task-based classification of RAG applications with count of publications. The word cloud is generated based on the publication counts\nlisted under various headings in Table 2.", "metadata": {"id": "6b1f252790e428ce3e716c42ac74bc690bb66e06", "source": "A Survey on RAG with LLMs.pdf", "page": 7, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "3788 Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790\n8 Arslan et al. / Procedia Computer Science 00 (2024) 000–000\nTable 3. Discipline-based classification of RAG applications. The detailed categories are derived from the \"Application area\"\ncolumn of Table 1. These categories are assigned based on a thorough comprehension of the study’s context.", "metadata": {"id": "fd8cd14042e6200223770e1707520089b4bd5280", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "1) Medical / Biomedical 5) Social and Communication\n- Biomedical QA [1] - Commonsense QA [6]\n- Medical QA [3] - Sentiments classification [13]\n- Medical text summarization [4] - Combating online hate speech [32]\n- Health education QA [14] - Retrieval-enhanced hashtags [31]\n- Identifying diseases [27] - Humanitarian assistance [19]\n- Clinical decision-making [9] - Chat with graphs [39]", "metadata": {"id": "ff72264fd014b83dfcf8057eaf2418acd5d176f8", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Clinical decision-making [9] - Chat with graphs [39]\n- Clinical-related writing [50] - Multicultural enterprise QA [40]\n- Science QA and scientific document classification [49] 6) Literature\n- Pharma industry regulatory compliance QA [51] - Book review generation guided by reference documents [5]\n2) Financial - Enhance user writing speed and accuracy [16]", "metadata": {"id": "2b99d8e459da833451395e53940a761821dd7e9b", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "2) Financial - Enhance user writing speed and accuracy [16]\n- Financial QA [2] - Generate stories with complex plots [23]\n- Automated cash transaction booking [47] 7) Other Categories\n3) Educational - Enterprise search [12]\n- Educational decision making [10] - Generate realistic and faithful images [21]\n- Textbook QA [11] - Decision-making applications [30]", "metadata": {"id": "718e007d68071704498c586083529be045be0e61", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Textbook QA [11] - Decision-making applications [30]\n4) Technology and Software Development - Open-domain question answering and fact verification [37]\n- Table QA [7] - Professional knowledge QA [38]\n- Technical product information QA [17] - Intelligence report generation [45]\n- Software development and maintenance [18, 22, 28, 42] - Short-form open-domain QA [46]", "metadata": {"id": "d1c0770634fbf3bdd9531d43af59ff260190ff08", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Software development and maintenance [18, 22, 28, 42] - Short-form open-domain QA [46]\n- Generative QA and informative conversations [20] - Question answering with private data [48]\n- Information extraction [29]\n- Text error correction [35]\n- Text-to-SQL translation [36]\n- Personalized dialogue systems [43]\n- Event argument (answer) extraction [44]\nDiscipline: (Count of Publications)", "metadata": {"id": "7ac878f3aec47095d9d8f2b3634a7cad30b87e3b", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "- Event argument (answer) extraction [44]\nDiscipline: (Count of Publications)\nMedical / Biomedical: (9)\nFinancial: (2)\nEducational: (2)\nTechnology and Software Development: (9)\nSocial and Communication: (7)\nLiterature (3)\nOther Categories: (8)\nFig. 5. Discipline-based classification of RAG applications with count of publications. The word cloud is generated based on the publication", "metadata": {"id": "9d7cef8a4fd2adff1e784361f9ffb4cce5d8ec2f", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "counts listed under various headings in Table 3.\nAcknowledgements\nThe authors thank the French Government and the National Research Agency (ANR) for their funding.\nReferences\n[1] Roumeliotis KI, Tselikas ND, & Nasiopoulos DK. (2024). “LLMs in e-commerce: a comparative analysis of GPT and LLaMA models in\nproduct review evaluation,” Natural Language Processing Journal:1-6:100056.", "metadata": {"id": "abb8c2fc8715182aadc4a4b1252537aafcb51d31", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "product review evaluation,” Natural Language Processing Journal:1-6:100056.\n[2] Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). “Language Models are Few-Shot\nLearners,” Advances in Neural Information Processing Systems 33 (NeurIPS 2020).\n[3] OpenAI, R. (2023). “Gpt-4 technical report,” arxiv 2303.08774. View in Article: 2(5).", "metadata": {"id": "df8e6b407057d95d81d838be1d385a26bac1be44", "source": "A Survey on RAG with LLMs.pdf", "page": 8, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790 3789\nArslan et al. / Procedia Computer Science 00 (2024) 000–000 9\n[4] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., ... & Wang, H. (2023). “Retrieval-augmented generation for large language models: A\nsurvey,” arXiv preprint arXiv:2312.10997.", "metadata": {"id": "c2181aea9886993fbfd22470a2cb6fa0b1a5873f", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "survey,” arXiv preprint arXiv:2312.10997.\n[5] Kandpal, N., Deng, H., Roberts, A., Wallace, E., & Raffel, C. (2023). “Large language models struggle to learn long-tail knowledge,” In\nInternational Conference on Machine Learning. PMLR: 5696-15707.\n[6] Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020). “Retrieval-augmented generation for knowledge-", "metadata": {"id": "1b55606fa85170df8639546d8ba3214afd9c9855", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "intensive nlp tasks,” Advances in Neural Information Processing Systems 33: 9459-9474.\n[7] Li, H., Su, Y., Cai, D., Wang, Y., & Liu, L. (2022). “A survey on retrieval-augmented text generation,” arXiv preprint arXiv:2202.01110.\n[8] Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., ... & Scialom, T. (2023). “Augmented language models: a", "metadata": {"id": "698011670cb019b82293d85e45d6ac2cffe4586f", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "survey,” arXiv preprint arXiv:2302.07842.\n[9] Zhao, R., Chen, H., Wang, W., Jiao, F., Do, X. L., Qin, C., ... & Joty, S. (2023). “Retrieving multimodal information for augmented\ngeneration: A survey,” arXiv preprint arXiv:2303.10868.\n[10] Xiong, G., Jin, Q., Lu, Z., & Zhang, A. (2024). “Benchmarking retrieval-augmented generation for medicine,” arXiv preprint\narXiv:2402.13178.", "metadata": {"id": "69c11b582d03d7e4aecd67f56f8f68467a028670", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "arXiv:2402.13178.\n[11] Jimeno Yepes, A., You, Y., Milczek, J., Laverde, S., & Li, L. (2024). “Financial Report Chunking for Effective Retrieval Augmented\nGeneration,” arXiv e-prints, arXiv-2402.\n[12] Yu, H., Guo, P., & Sano, A. (2023). “Zero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation,”\nIn Machine Learning for Health (ML4H) PMLR: 650-663.", "metadata": {"id": "7bf4c70fd1153aa0b43f5433ee031d89351aa940", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "In Machine Learning for Health (ML4H) PMLR: 650-663.\n[13] Manathunga, S. S., & Illangasekara, Y. A. (2023). “Retrieval Augmented Generation and Representative Vector Summarization for large\nunstructured textual data in Medical Education,” arXiv preprint arXiv:2308.00479.", "metadata": {"id": "6346c3893d15333988f43c3cda698f753b23d530", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "unstructured textual data in Medical Education,” arXiv preprint arXiv:2308.00479.\n[14] Kim, J., Choi, S., Amplayo, R. K., & Hwang, S. W. (2020). “Retrieval-augmented controllable review generation,” In Proceedings of the\n28th International Conference on Computational Linguistics: 2284-2295.", "metadata": {"id": "02213976afafc87a55020faca4abbfd417b066ed", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "28th International Conference on Computational Linguistics: 2284-2295.\n[15] Sha, Y., Feng, Y., He, M., Liu, S., & Ji, Y. (2023). “Retrieval-augmented Knowledge Graph Reasoning for Commonsense Question\nAnswering,” Mathematics 11(15): 3269; https://doi.org/10.3390/math11153269.", "metadata": {"id": "b5704f9584141be218385f11fdab4ea778bf332f", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Answering,” Mathematics 11(15): 3269; https://doi.org/10.3390/math11153269.\n[16] Pan, F., Canim, M., Glass, M., Gliozzo, A., & Hendler, J. (2022). “End-to-End Table Question Answering via Retrieval-Augmented\nGeneration,” arXiv preprint arXiv:2203.16714.\n[17] Ge, J., Sun, S., Owens, J., Galvez, V., Gologorskaya, O., Lai, J. C., ... & Lai, K. (2023). “Development of a Liver Disease-Specific Large", "metadata": {"id": "7a9f21959f92d8a06e7bcad41d12aa354bc8ce9b", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Language Model Chat Interface using Retrieval Augmented Generation,” medRxiv.\n[18] Zakka, C., Shad, R., Chaurasia, A., Dalal, A. R., Kim, J. L., Moor, M., ... & Hiesinger, W. (2024). “Almanac—retrieval-augmented language\nmodels for clinical medicine,” NEJM AI 1(2), AIoa2300068.", "metadata": {"id": "75c4e164dd57a897a2daac8eb1f42c5ff89c155d", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "models for clinical medicine,” NEJM AI 1(2), AIoa2300068.\n[19] Han, Z. FeiFei, Lin, J., Gurung, A., Thomas, D. R., Chen, E., Borchers, C., Gupta, S., & Koedinger, K. R. (2024). “Improving Assessment of\nTutoring Practices using Retrieval-Augmented Generation,” arXiv preprint arXiv:2402.14594.", "metadata": {"id": "76ad28d8adf581e523697e4b22366264d5bf323a", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Tutoring Practices using Retrieval-Augmented Generation,” arXiv preprint arXiv:2402.14594.\n[20] Alawwad, H. A., Alhothali, A., Naseem, U., Alkhathlan, A., & Jamal, A. (2024). “Enhancing Textbook Question Answering Task with\nLarge Language Models and Retrieval Augmented Generation,” arXiv preprint arXiv:2402.05128.", "metadata": {"id": "5668647127972e1e26136573e7ed5dcf851e20a4", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Large Language Models and Retrieval Augmented Generation,” arXiv preprint arXiv:2402.05128.\n[21] Bucur, M. (2023). “Exploring Large Language Models and Retrieval Augmented Generation for Automated Form Filling,” (Bachelor's\nthesis, University of Twente).\n[22] Zhang, B., Yang, H., Zhou, T., Ali Babar, M., & Liu, X. Y. (2023). “Enhancing financial sentiment analysis via retrieval augmented large", "metadata": {"id": "7eefa9503d64d35cc73a6cdf7b1b5306200a2712", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "language models,” In Proceedings of the Fourth ACM International Conference on AI in Finance: 349-356.\n[23] Al Ghadban, Y., Lu, H. Y., Adavi, U., Sharma, A., Gara, S., Das, N., ... & Hirst, J. E. (2023). “Transforming healthcare education:\nHarnessing large language models for frontline health worker capacity building using retrieval-augmented generation,” medRxiv, 2023-12.", "metadata": {"id": "a8c3aa091dbf28481ebc3ee151d6eac3f5f86fa4", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "[24] Jeong, M., Sohn, J., Sung, M., & Kang, J. (2024). “Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-\nAugmented Large Language Models,” arXiv preprint arXiv:2401.15269.\n[25] Xia, M., Zhang, X., Couturier, C., Zheng, G., Rajmohan, S., & Ruhle, V. (2023). “Hybrid retrieval-augmented generation for real-time", "metadata": {"id": "5bb1707ecd560ab3c655f459ece6c341778f706e", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "composition assistance,” arXiv preprint arXiv:2308.04215.\n[26] Rackauckas, Z. (2024). “RAG-Fusion: A New Take on Retrieval-Augmented Generation,” arXiv preprint arXiv:2402.03367.\n[27] Shi, E., Wang, Y., Tao, W., Du, L., Zhang, H., Han, S., ... & Sun, H. (2022). “RACE: Retrieval-Augmented Commit Message\nGeneration,” arXiv preprint arXiv:2203.02700.", "metadata": {"id": "3cf51bb6046372a6e0467d7444a60e621ccc3278", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Generation,” arXiv preprint arXiv:2203.02700.\n[28] Colverd, G., Darm, P., Silverberg, L., & Kasmanoff, N. (2023). “FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented\nGeneration with an LLM,” arXiv preprint arXiv:2311.02597.\n[29] Huang, W., Lapata, M., Vougiouklis, P., Papasarantopoulos, N., & Pan, J. (2023). “Retrieval Augmented Generation with Rich Answer", "metadata": {"id": "76d73301865ba9923f74b988babc84e00a4591fb", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Encoding,” In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-\nPacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers): 1012-1025.\n[30] Chen, W., Hu, H., Saharia, C., & Cohen, W. W. (2022). “Re-imagen: Retrieval-augmented text-to-image generator,” arXiv preprint\narXiv:2209.14491.", "metadata": {"id": "f51d5cd956f810db1b3f03d9ff74e99b325cb205", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "arXiv:2209.14491.\n[31] Lu, S., Duan, N., Han, H., Guo, D., Hwang, S. W., & Svyatkovskiy, A. (2022). “Reacc: A retrieval-augmented code completion\nframework,” arXiv preprint arXiv:2203.07722.\n[32] Wen, Z., Tian, Z., Wu, W., Yang, Y., Shi, Y., Huang, Z., & Li, D. (2023). “Grove: a retrieval-augmented complex story generation\nframework with a forest of evidence,” arXiv preprint arXiv:2310.05388.", "metadata": {"id": "c0d0ae3865247028cd2c5e971329f0b5c0c86760", "source": "A Survey on RAG with LLMs.pdf", "page": 9, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "3790 Muhammad Arslan et al. / Procedia Computer Science 246 (2024) 3781–3790\n10 Arslan et al. / Procedia Computer Science 00 (2024) 000–000\n[33] Li, S., Park, S., Lee, I., & Bastani, O. (2023). “TRAC: Trustworthy Retrieval Augmented Chatbot,” arXiv preprint arXiv:2307.04642.", "metadata": {"id": "d617566e9fd38a9dcc59a1d5fb3239923e68ce0d", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "[34] Lozano, A., Fleming, S. L., Chiang, C. C., & Shah, N. (2023). “Clinfo. ai: An open-source retrieval-augmented large language model system\nfor answering medical questions using scientific literature,” In Pacific symposium on Biocomputing 2024: 8-23.\n[35] Ding, W., Cao, Y., Zhao, D., Xiao, C., & Pavone, M. (2023). “RealGen: Retrieval Augmented Generation for Controllable Traffic", "metadata": {"id": "a2393a995a4c8a56e719c1e2f5719e4b1ca44bba", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Scenarios,” arXiv preprint arXiv:2312.13303.\n[36] Thompson, W. E., Vidmar, D. M., De Freitas, J. K., Pfeifer, J. M., Fornwalt, B. K., Chen, R., ... & Miotto, R. (2023). “Large Language\nModels with Retrieval-Augmented Generation for Zero-Shot Disease Phenotyping,” arXiv preprint arXiv:2312.06457.", "metadata": {"id": "7a5ef9c6452f0ce2dea204f66f72968859500c86", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "[37] Wang, W., Wang, Y., Joty, S., & Hoi, S. C. (2023). “Rap-gen: Retrieval-augmented patch generation with codet5 for automatic program\nrepair,” In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software\nEngineering: 146-158.", "metadata": {"id": "e02cb9f80c502f390a7f03ae40038878bd4033df", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Engineering: 146-158.\n[38] Guo, Y., Li, Z., Jin, X., Liu, Y., Zeng, Y., Liu, W., ... & Cheng, X. (2023). “Retrieval-augmented code generation for universal information\nextraction,” arXiv preprint arXiv:2311.02962.\n[39] Kagaya, T., Yuan, T. J., Lou, Y., Karlekar, J., Pranata, S., Kinose, A., ... & You, Y. (2024). “RAP: Retrieval-Augmented Planning with", "metadata": {"id": "2b6c3448f95c8decab2b60af53835f6c01dd7380", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Contextual Memory for Multimodal LLM Agents,” arXiv preprint arXiv:2402.03610.\n[40] Fan, R. Z., Fan, Y., Chen, J., Guo, J., Zhang, R., & Cheng, X. (2023). “RIGHT: Retrieval-augmented Generation for Mainstream Hashtag\nRecommendation,” arXiv preprint arXiv:2312.10466.", "metadata": {"id": "4e813416de84ad3fae2dd607d5ca582b32f158d2", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Recommendation,” arXiv preprint arXiv:2312.10466.\n[41] Jiang, S., Tang, W., Chen, X., Tanga, R., Wang, H., & Wang, W. (2023). Raucg: Retrieval-augmented unsupervised counter narrative\ngeneration for hate speech. arXiv preprint arXiv:2310.05650.\n[42] Xu, R., Yu, Y., Ho, J., & Yang, C. (2023). “Weakly-supervised scientific document classification via retrieval-augmented multi-stage", "metadata": {"id": "79013598d023e7393b2abfbf6f4c942385388500", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "training,” In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval: 2501-\n2505.\n[43] Hu, M., Zhao, X., Wei, J., Wu, J., Sun, X., Li, Z., ... & Zhang, Y. (2023). “rT5: A Retrieval-Augmented Pre-trained Model for Ancient", "metadata": {"id": "69fbeccc73352f69f1c1b17f4e7d00a232759a48", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Chinese Entity Description Generation,” In International Conference on NLP and Chinese Computing. Cham: Springer: 736-748.\n[44] Song, S., Lv, Q., Geng, L., Cao, Z., & Fu, G. (2023). “RSpell: Retrieval-augmented Framework for Domain Adaptive Chinese Spelling\nCheck,” In CCF International Conference on Natural Language Processing and Chinese Computing. Cham: Springer: 551-562.", "metadata": {"id": "0d1bcb902fa7b68a754820798c00d8cc886a4ff2", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "[45] Shi, P., Zhang, R., Bai, H., & Lin, J. (2022). “Xricl: Cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql\nsemantic parsing,” arXiv preprint arXiv:2210.13693.\n[46] Asai, A., Wu, Z., Wang, Y., Sil, A., & Hajishirzi, H. (2023). “Self-rag: Learning to retrieve, generate, and critique through self-\nreflection,” arXiv preprint arXiv:2310.11511.", "metadata": {"id": "15c10bdc4ec204daf0036d990e900601274f977f", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "reflection,” arXiv preprint arXiv:2310.11511.\n[47] Lin, D. (2024). “Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition,” arXiv preprint\narXiv:2401.12599.\n[48] He, X., Tian, Y., Sun, Y., Chawla, N. V., Laurent, T., LeCun, Y., ... & Hooi, B. (2024). “G-Retriever: Retrieval-Augmented Generation for", "metadata": {"id": "94ab52cd3e5bbe15d8aa0fb55133d56f6b8b5fc8", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Textual Graph Understanding and Question Answering,” arXiv preprint arXiv:2402.07630.\n[49] Ahmad, S. R. (2024). “Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments: A RAG Model\nImplementation for Multicultural Enterprise,” arXiv preprint arXiv:2401.01511.", "metadata": {"id": "283999c688451d4ddf806bc1e8fce30d1028b8de", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Implementation for Multicultural Enterprise,” arXiv preprint arXiv:2401.01511.\n[50] Zhao, C., Jiang, Y., Qiu, Y., Zhang, H., & Yang, W. Y. (2023). “Differentiable Retrieval Augmentation via Generative Language Modeling\nfor E-commerce Query Intent Classification,” In Proceedings of the 32nd ACM International Conference on Information and Knowledge\nManagement: 4445-4449.", "metadata": {"id": "368f524ec508ad6a946c4139e3c4d75e123a3931", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Management: 4445-4449.\n[51] Nakhod, o. Using retrieval-augmented generation to elevate low-code developer skills. https://doi.org/10.15407/jai2023.03.126\n[52] Wang, H., Huang, W., Deng, Y., Wang, R., Wang, Z., Wang, Y., ... & Wong, K. F. (2024). “UniMS-RAG: A Unified Multi-source\nRetrieval-Augmented Generation for Personalized Dialogue Systems,” arXiv preprint arXiv:2401.13256.", "metadata": {"id": "10d66629f6dc84e962bb6ce3b45bae03c3a7ec1b", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Retrieval-Augmented Generation for Personalized Dialogue Systems,” arXiv preprint arXiv:2401.13256.\n[53] Du, X., & Ji, H. (2022). “Retrieval-augmented generative question answering for event argument extraction,” arXiv preprint\narXiv:2211.07067.\n[54] Ranade, P., & Joshi, A. (2023). “FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction,” arXiv", "metadata": {"id": "2c18710c4a5afb08b8fdfa8b37ddfe6632390b51", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "preprint arXiv:2310.13848.\n[55] Zhang, Z., Fang, M., & Chen, L. (2024). “RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain\nQuestion Answering,” arXiv preprint arXiv:2402.16457.\n[56] Zhang, S., Yadav, D., & Jin, T. (2023). “Cash transaction booking via retrieval augmented LLM. KDD 2023 Workshop on Robust NLP for", "metadata": {"id": "7f3907d59a9e6fc202121ea7f9b19c87955fa0b7", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "Finance (RobustFin),” https://www.amazon.science/publications/cash-transaction-booking-via-retrieval-augmented-llm\n[57] Pouplin, T., Sun, H., Holt, S., & Van der Schaar, M. (2024). “Retrieval-Augmented Thought Process as Sequential Decision Making,” arXiv\npreprint arXiv:2402.07812.", "metadata": {"id": "8c3f487fcc5ebc7638af2198e88c321c5fdcff66", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "preprint arXiv:2402.07812.\n[58] Munikoti, S., Acharya, A., Wagle, S., & Horawalavithana, S. (2023). “ATLANTIC: Structure-Aware Retrieval-Augmented Language Model\nfor Interdisciplinary Science,” arXiv preprint arXiv:2311.12289.\n[59] Markey, N., El-Mansouri, I., Rensonnet, G., van Langen, C., & Meier, C. (2024). “From RAGs to riches: Using large language models to", "metadata": {"id": "a71ebff3900441b8ad9791aba22a59dfb6937a2d", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
{"content": "write documents for clinical trials,” arXiv preprint arXiv:2402.16406.\n[60] Kim, J., & Min, M. (2024). “From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical Regulatory Compliance Process,” arXiv\npreprint arXiv:2402.01717.", "metadata": {"id": "6ca42d0a9128e1dda9575ac7d57eda4a218820df", "source": "A Survey on RAG with LLMs.pdf", "page": 10, "created_at": "2025-09-07T18:33:16Z"}}
