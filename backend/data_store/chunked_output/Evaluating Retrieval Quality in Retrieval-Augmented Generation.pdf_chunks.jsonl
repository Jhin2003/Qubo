{"content": "Evaluating Retrieval Quality in Retrieval-Augmented Generation\nAlirezaSalemi HamedZamani\nUniversityofMassachusettsAmherst UniversityofMassachusettsAmherst\nAmherst,MA,UnitedStates Amherst,MA,UnitedStates\nasalemi@cs.umass.edu zamani@cs.umass.edu\nABSTRACT withgenerativemodels[10,23].Traditionally,RAGevaluationhas\nEvaluatingretrieval-augmentedgeneration(RAG)presentschal- primarilyreliedonend-to-endassessment,whichentailscompar-\nlenges,particularlyforretrievalmodelswithinthesesystems.Tra- ingthegeneratedoutputwithoneormoregroundtruthreferences", "metadata": {"id": "3fdb388d71e97bf322c775ce8dc24afe274226de", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "ditionalend-to-endevaluationmethodsarecomputationallyexpen- [20].Whilethisiscrucial,itpresentsseverallimitations,especially,\nsive.Furthermore,evaluationoftheretrievalmodel’sperformance forevaluatingretrievalmodelsinRAGsystems.\nbasedonquery-documentrelevancelabelsshowsasmallcorrela- First,end-to-endevaluationlackstransparencyregardingwhich\ntionwiththeRAGsystem’sdownstreamperformance.Wepropose retrieveddocumentcontributedtothegeneratedoutput,hindering\nanovelevaluationapproach,eRAG,whereeachdocumentinthe interpretabilityofthesystem’sbehavior.Secondly,itisresource-", "metadata": {"id": "9ab748313a8ea644f3827c98dddd44a01e16f6fa", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "retrievallistisindividuallyutilizedbythelargelanguagemodel intensive,consumingsignificanttimeandcomputationalpower,\nwithintheRAGsystem.Theoutputgeneratedforeachdocumentis particularlywhendealingwithalargesetofretrievalresultscon-\nthenevaluatedbasedonthedownstreamtaskgroundtruthlabels. sumedbytheLLM.Toprocesslonginputsequencesresultingfrom\nInthismanner,thedownstreamperformanceforeachdocument theutilizationofallretrieveddocumentsbytheLLM,GPUswith\nservesasitsrelevancelabel.Weemployvariousdownstreamtask substantialmemorycapacitiesareessentialforend-to-endevalu-", "metadata": {"id": "eb30ee25615ed7568b28b9f96372a1eca1853890", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "metricstoobtaindocument-levelannotationsandaggregatethem ation.Moreover,manyrankingsystemsrelyoninterleaving(i.e.,\nusingset-basedorrankingmetrics.Extensiveexperimentsona replacingoneormoredocumentsintheresultlist)forevaluation\nwiderangeofdatasetsdemonstratethateRAGachievesahigher and optimization, which further complicates the evaluation, as\ncorrelationwithdownstreamRAGperformancecomparedtobase- slightvariationsinretrievalresultsnecessitatere-computationof\nlinemethods,withimprovementsinKendall’s𝜏correlationranging theRAGpipeline.Finally,optimizingrankingmodelsoftenrequires", "metadata": {"id": "107df173b7dfc4020c2c9067683408616eb8cc63", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "from0.168to0.494.Additionally,eRAGofferssignificantcompu- document-levelfeedback,suchasuserclicks[3,6].However,end-\ntationaladvantages,improvingruntimeandconsumingupto50 to-endevaluationonlyprovideslist-levelfeedbackfortheretrieval\ntimeslessGPUmemorythanend-to-endevaluation. results.Thatsaid,thispaperstudiesretrievalevaluationinRAG.\nHumanannotationscanbeapotentialsolutionforevaluating\nCCSCONCEPTS retrievalmodelsinRAG,however,accurateannotationsareoften\nchallengingandcostlytoobtain.Morerecently,withtheemergence\n•Computingmethodologies→Naturallanguagegeneration;", "metadata": {"id": "b682742b73d0e99c31a5096d31b38fafbf10351a", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "•Computingmethodologies→Naturallanguagegeneration;\noflargelanguagemodels(LLMs)andtheiradvancedcapabilities\n•Informationsystems→Evaluationofretrievalresults.\ninreasoningandtextcomprehension,theyhavebeenutilizedto\nannotatedocumentsforretrievalevaluation[10,23].Nevertheless,\nKEYWORDS\ntheseapproachespredominantlyevaluatetheretrieverinRAGsys-\nEvaluation;retrievalquality;retrieval-augmentedgeneration\ntemsbasedonhumanpreferences,whereastheprimaryobjective\nACMReferenceFormat: oftheretrievalmodelinRAGistoservetheLLMthatleverages", "metadata": {"id": "4d84cbabb448988edbf14cb84c4612f35a9ed39d", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "ACMReferenceFormat: oftheretrievalmodelinRAGistoservetheLLMthatleverages\nAlirezaSalemiandHamedZamani.2024.EvaluatingRetrievalQualityin theretrievedresults[35].Thatsaid,ourextensiveinvestigationon\nRetrieval-AugmentedGeneration.InProceedingsofthe47thInternational adiversesetofRAGsystemsforopen-domainquestionanswer-\nACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval ing,factverification,anddialoguesystemsrevealsthatemploying\n(SIGIR’24),July14–18,2024,Washington,DC,USA.ACM,NewYork,NY, humanannotations,suchastheprovenancelabelsintheKILTbench-", "metadata": {"id": "7fd544b5618bce0e03dfe0c1595c0c4cfe5cf666", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "USA,6pages.https://doi.org/10.1145/3626772.3657957\nmark[20],forevaluatingtheretrievalmodelswithinaRAGsystem\nexhibitsonlyaminorcorrelationwiththedownstreamRAGper-\n1 INTRODUCTION\nformance.Thisindicatesalackofmeaningfulrelationshipbetween\nRetrieval-augmentedgeneration(RAG)hasemergedasaprominent theevaluatedmetricsandthedownstreamperformanceofRAG.\napproachinnaturallanguageprocessing,combiningthestrengths Inthispaper,weproposeeRAG,anewapproachforevaluating\nofretrievalandgenerationmodels[35],withusecasesindecreas- retrieversinRAGsystems,whereweapplytheLLMinRAGsystem", "metadata": {"id": "aeaa40a92c131e796682cced292ca432e934a1fd", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "ing hallucination [1, 29], knowledge-grounding [9, 16, 34], and oneachdocumentintheretrievalresultlistindividuallyanduse\npersonalization[25,26].EvaluatingRAGsystemsisimportantas theLLM’soutputtoprovidedocument-levelannotations.These\nitensurestheeffectivenessofintegratingretrieval-basedmethods annotationscanbeobtainedusinganyarbitrarydownstreamtask\nmetric,suchasaccuracy,exactmatch,orROUGE[17].Wecanthen\nThisworkislicensedunderaCreativeCommonsAttribution applyaset-basedorrankingmetricasanaggregationfunctionto\nInternational4.0License.\nobtainasingleevaluationscoreforeachretrievalresultlist.", "metadata": {"id": "55a5eb82958ca4aa85be26546bfdc0cfc3b29087", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "International4.0License.\nobtainasingleevaluationscoreforeachretrievalresultlist.\nWeevaluateourproposedapproachonquestionanswering,fact-\nSIGIR’24,July14–18,2024,Washington,DC,USA\nchecking,anddialoguegenerationfromtheknowledge-intensive\n©2024Copyrightheldbytheowner/author(s).\nACMISBN979-8-4007-0431-4/24/07. languagetasks(KILT)benchmark[20].Ourresultsdemonstratethat\nhttps://doi.org/10.1145/3626772.3657957\n2395", "metadata": {"id": "188a8680b2b90132460093cd810cb8286345b664", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 1, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "SIGIR’24,July14–18,2024,Washington,DC,USA AlirezaSalemiandHamedZamani\nourproposedapproachachievesthehighestcorrelationwiththe where𝑦istheexpecteddownstreamoutputforthequery.Wecan\ndownstreamperformanceoftheRAGsystemincomparisonwith employthecreatedG𝑞 toutilizeanyrankingmetrictoevaluateR.\nthebaselines.Specifically,weobserveanabsoluteimprovementin Notethattheruntimecostofavanillatransformer[32]scales\nKendall’staucorrelationrangingbetween0.168and0.494acrossthe quadraticallywithitsinputlength.Consequently,forend-to-end", "metadata": {"id": "451c4dfc877cfdef512d6fb8442ee6fe080da7a1", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "evaluateddatasets.Furthermore,weinvestigatetheimpactofdiffer- evaluation,thecostofrunningatransformeronarankedlistwith\nentretrievalaugmentationmethods,thequantityofretrieveddocu- 𝑘 documents,withanaveragelengthof𝑑,togenerateanoutput\nments,andtheLLMsizeoncorrelation.Finally,wedemonstratethat withlength𝑙 is𝑂(𝑙𝑘2𝑑2).Conversely,inourapproach,aseach\nourapproachofferssignificantcomputationaladvantages,consum- documentisindividuallyfedtotheLLMforktimes,thecostis\ningupto50timeslessmemorycomparedtoend-to-endevaluation. 𝑂(𝑙𝑘𝑑2),provingtobemoreefficientthanend-to-endevaluation.", "metadata": {"id": "310d5b85f2837ce00a3ef7958aee09f061181316", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Tofacilitateresearchinthisdomain,wemakeeRAG’simplementa-\nRetrievalEvaluationMetrics. ForarankedlistR𝑘,comprising\ntionpubliclyavailableat:https://github.com/alirezasalemi7/eRAG.\n𝑘retrieveddocumentsgeneratedbyaretrievalmodelR,anevalua-\ntionmetricE\nR\nassignsascoreE\nR\n(R𝑘 ,G𝑞) ∈ [0,1],bycomparing\n2 EVALUATINGRETRIEVERSINRAG\ntherankedlistwiththerelevancescoresG𝑞,whichisafunctionthat\nGenerally,twopredominantmethodsareusedforobtainingrele- mapseachdocumenttoascalarrelevancescoreforthedocument", "metadata": {"id": "508a52e9161ff4c0f652f9d0e4ae69aec598f131", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "vancelabelsforretrievalevaluation.Thefirstapproachinvolves withrespecttothequery𝑞(i.e.,G𝑞(𝑑)=𝑠 𝑑).Variousdefinitionsex-\nhumanjudgmenttoassesstherelevanceofaquerytodocuments istfortheevaluationmetricE R;inthispaper,weexaminePrecision\nwithinacorpus.Themainissuewiththisapproachisthathuman (P),Recall(R),MeanAveragePrecision(MAP),MeanReciprocal\nannotationcanbecostlyandisoftenimpracticalforevaluatingall Rank(MRR)[2],NormalizedDiscountedCumulativeGain(NDCG)\ndocumentsinacorpus[28].Moreover,humanannotationrelies [11],andHitRate.Notethatwhendealingwithnon-binaryrele-", "metadata": {"id": "b36b86ef707e74b3c7f941e96855748cb141edb5", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "onhumanpreferencestojudgetherelevanceofdocumentstoa vancelabels,precisionconsiderstheaveragevalueofrelevance\nquery. However, a documentdeemed relevant based on human labels,whileHitRatioconsidersthemaximumvalueamongthem.\npreferencesmaynotbeusefulforanLLMinfulfillingitstask.\nThesecondapproachutilizesthedownstreamgroundtruthout- 3 EXPERIMENTS\nputassociatedwiththequerytoprovideweakrelevancelabels. 3.1 Setup\nInthismethod,aretrieveddocumentcontainingthedownstream\nDatasetsandEvaluation. WeuseNaturalQuestions(NQ)[15],\ngroundtruthisconsideredrelevant[8,14,24,27].Thismethodalso", "metadata": {"id": "a0394353870614a5d2768252e1716c416b6f4749", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "groundtruthisconsideredrelevant[8,14,24,27].Thismethodalso\nTriviaQA[13],HotpotQA[33],FEVER[31],andWizardofWikipedia\npresentsitsownchallenges.Thisapproachisimpractical,partic-\n(WoW)[4]datasetsfromtheKILT[20]benchmark.Duetotheun-\nularlyinscenarioswherethetaskinvolveslong-textgeneration\navailabilityofgroundtruthlabelsforthetestset,weutilizethe\nortextclassification,asdownstreamtasklabelsmightnotexist\npubliclyaccessiblevalidationset.Astheretrievalcorpus,weemploy\nwithindocuments.Also,onedocumentcanbeusefulforanLLM\ntheWikipediadumpoftheKILTbenchmarkandadheretothepre-", "metadata": {"id": "4137eebc793dc965f99d905a36d15043bfa3c330", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "theWikipediadumpoftheKILTbenchmarkandadheretothepre-\ninfulfillingitstaskwithoutcontainingthegroundtruthlabels.\nprocessingoutlinedbyKarpukhinetal.[14],whereeachdocument\nEven though we are not aware any work that use LLMs for\nissegmentedintopassages,eachconstrainedtoamaximumlength\nevaluatingretrievalmodelsinRAG,LLMscanbeleveragedtola-\nof100words.Theconcatenationofthearticletitleandpassage\nbeldocumentsbasedontheirrelevancetoaquery.Inspiredby\nisusedasadocument.TheKILTbenchmarkfurnishesdocument-\nThomasetal.[30],theLLMfunctionsasabinaryclassifier,indi-", "metadata": {"id": "6df1805b055369b2f00d2885e40005c314453176", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Thomasetal.[30],theLLMfunctionsasabinaryclassifier,indi-\nlevelrelevancelabels(calledProvenance)foritsdatasets,andthese\ncatingwhetheradocumentisrelevanttothequeryornot.The\nareemployedforevaluatingretrievalperformance.Inlinewith\nmentionedchallengespersistevenwiththejudgmentofLLMs,espe-\nourpreprocessingmethod,wedefineallpassageswithinapositive\nciallyiftheLLMresponsibleforlabelingdiffersfromtheLLMinthe\ndocumentaspositivepassagesforourevaluation.Forrelevance\nRAGpipeline.Besides,employingLLMsasjudgesinthisscenario\nevaluationusinganLLM,weemployMistral1[12]toannotateeach", "metadata": {"id": "e3017bc981b14106e13a37149c751f9c778fed5b", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "evaluationusinganLLM,weemployMistral1[12]toannotateeach\ncanposechallengesduetothecomputationalcostofrunningthem\ndocumentwithintheretrievedlist,determiningwhetheritisrele-\nonalargesetofretrieveddocumentsandmemoryconstraints.\nvanttothequeryornot.Weadoptthemetricsrecommendedby\nTomitigatetheseproblems,weproposeeRAG,anovelapproach\ntheKILTbenchmark,namelyExactMatch(EM)forNQ,TriviaQA,\nthatinvolvesutilizingtheLLMinRAGsystemitselfasthearbiter\nandHotpotQA,AccuracyforFEVER,andF1fortheWoWdataset.\nforgeneratinglabelstoevaluatetheretrievalmodel.\nExperimentsConfiguration. Inallexperiments,unlessexplicitly", "metadata": {"id": "acf31098d8793a6048b965222952d1a2a2830fe0", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "ExperimentsConfiguration. Inallexperiments,unlessexplicitly\nUsingDownstreamLargeLanguageModelinRAGasDoc-\nstatedotherwise,weemployT5-small[21]withFusion-in-Decoder\numentAnnotator. ConsideraretrievalmodelR thatproduces\n(FiD)[9]astheLLM.WeemployAdamW[19]withaweightdecay\narankedlistR𝑘 with𝑘 documentsfortheLLMM taskedwith of10−2andalearningrateof5×10−5for10epochs,incorporating\nperformingaspecifictask,utilizingadownstreamevaluationfunc-\nlinearwarmupfortheinitial5%oftrainingsteps.Theeffective\ntionE M.TheLLMMtakesarankedlistofdocumentsasitsinput\nbatchsizeissetto64.EachmodelistrainedusinganA100Nvidia", "metadata": {"id": "bb7391b396a6d069ebb2e1bc31e80f4711098e9d", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "batchsizeissetto64.EachmodelistrainedusinganA100Nvidia\nalongwiththequery𝑞,andgeneratesanoutputrepresentedas\nGPU.Fordocumentretrievalduringtraining,weutilizeBM25[22]\n𝑦¯=M(𝑞,R𝑘).ForthedocumentsinR𝑘,wefeedeachdocumentin-\nimplementedinPyserini[18]toretrieve50documentstoaugment\ndividuallytotheLLMMwiththequeryandevaluatethegenerated\ntheinputwiththem.Forfastvectorsearchindenseretrievalwith\nanswertocreatethelabelforeachdocument,expressedas: Contriever2[7],weuseFaiss[5]flatindex.\n1https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2", "metadata": {"id": "e0f7bd03cfe5030937a2e277ea6fbc68fdb4bd9a", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "1https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\nG𝑞[𝑑] =E M (M(𝑞,{𝑑}),𝑦) : ∀𝑑 ∈R𝑘 (1) 2https://huggingface.co/facebook/contriever\n2396", "metadata": {"id": "9e9d7e443aea1a824ea5471283e078c284b47dda", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 2, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "EvaluatingRetrievalQualityinRetrieval-AugmentedGeneration SIGIR’24,July14–18,2024,Washington,DC,USA\nTable1:ThecorrelationbetweeneachevaluationapproachandthedownstreamperformanceoftheLLM.T5-smallwithFiD\nwith50retrieveddocumentsisused.WedonotreportcorrelationfortheAnswersmethodforFEVERandWOWdatasets\nbecausetheanswerstoqueriesdonotexistinthedocumentsinceFEVERisaclassificationdatasetandWoWislong-text\ngeneration.FortheWoWdataset,weonlyreportcorrelationonPrecisionandHitRatiobecauseothermetricsdonotsupport\nnon-integerrelevancelabels.TauisKendall’stauandrhoisSpearman’srho.\nBM25 Contriever\nRelevance", "metadata": {"id": "58f16a3f24ebe1f09efc8168e99324727823fb6e", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "non-integerrelevancelabels.TauisKendall’stauandrhoisSpearman’srho.\nBM25 Contriever\nRelevance\nAnnotation Metric NQ TriviaQA HotpotQA FEVER WoW NQ TriviaQA HotpotQA FEVER WoW\ntau rho tau rho tau rho tau rho tau rho tau rho tau rho tau rho tau rho tau rho\nMAP 0.349 0.417 0.298 0.364 0.359 0.423 - - - - 0.303 0.366 0.265 0.325 0.379 0.429 - - - -\nMRR 0.361 0.417 0.313 0.340 0.398 0.449 - - - - 0.301 0.353 0.257 0.292 0.384 0.430 - - - -\nContaining\nNDCG 0.357 0.427 0.298 0.365 0.370 0.435 - - - - 0.313 0.378 0.270 0.331 0.385 0.437 - - - -\nthe", "metadata": {"id": "9a3e89a5c998f628679aa1b309fb8e9840aa8612", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "NDCG 0.357 0.427 0.298 0.365 0.370 0.435 - - - - 0.313 0.378 0.270 0.331 0.385 0.437 - - - -\nthe\nAnswer P 0.353 0.411 0.276 0.333 0.396 0.454 - - - - 0.346 0.403 0.283 0.340 0.406 0.449 - - - -\nR 0.325 0.325 0.232 0.232 0.375 0.375 - - - - 0.319 0.319 0.215 0.215 0.401 0.401 - - - -\nHitRatio 0.325 0.325 0.232 0.232 0.375 0.375 - - - - 0.319 0.319 0.215 0.215 0.401 0.401 - - - -\nMAP 0.181 0.218 0.142 0.172 0.007 0.009 0.026 0.032 0.015 0.021 0.161 0.196 0.113 0.137 0.128 0.155 0.045 0.056 0.055 0.080", "metadata": {"id": "043db5299ca44696633c8cbd2a58fb7979e45f9f", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "MRR 0.177 0.205 0.151 0.175 0.074 0.080 0.036 0.040 0.013 0.017 0.152 0.173 0.120 0.136 0.151 0.169 0.045 0.049 0.059 0.081\nKILT NDCG 0.179 0.216 0.142 0.172 0.021 0.026 0.029 0.036 0.013 0.019 0.159 0.193 0.115 0.140 0.134 0.162 0.045 0.056 0.056 0.081\nProvenance P 0.163 0.192 0.140 0.165 0.139 0.164 0.043 0.051 0.011 0.015 0.131 0.157 0.108 0.130 0.181 0.215 0.033 0.040 0.045 0.064\nR 0.216 0.216 0.187 0.187 0.113 0.113 0.050 0.050 0.019 0.023 0.157 0.157 0.135 0.135 0.163 0.163 0.038 0.038 0.056 0.068", "metadata": {"id": "5db2bd0232d3086ad46d611a5c844bafb65f1a60", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "HitRatio 0.216 0.216 0.187 0.187 0.113 0.113 0.050 0.050 0.019 0.023 0.157 0.157 0.135 0.135 0.163 0.163 0.038 0.038 0.056 0.068\nMAP 0.045 0.055 0.176 0.216 0.034 0.042 0.018 0.022 -0.005 -0.008 0.032 0.039 0.174 0.213 0.051 0.063 0.021 0.026 -0.002 -0.003\nRelevance MRR 0.060 0.062 0.189 0.196 0.001 0.001 -0.021 -0.022 -0.008 -0.011 0.048 0.050 0.143 0.151 0.034 0.038 -0.007 -0.007 0.004 0.005\nAnnotation NDCG 0.049 0.060 0.178 0.218 0.032 0.039 0.018 0.022 -0.006 -0.009 0.036 0.044 0.175 0.214 0.049 0.060 0.022 0.028 0.000 0.000", "metadata": {"id": "284138b870be2325f543267387ca4276dd29b541", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "withLLM P 0.028 0.034 0.137 0.166 -0.004 -0.006 0.021 0.025 -0.005 -0.008 0.002 0.003 0.138 0.167 0.010 0.013 0.014 0.017 -0.006 -0.010\n(Mistral7B) R 0.014 0.014 0.032 0.032 -0.016 -0.016 0.019 0.019 0.003 0.003 0.000 0.000 0.039 0.039 -0.042 -0.042 -0.017 -0.017 0.017 0.021\nHitRatio 0.014 0.014 0.032 0.032 -0.016 -0.016 0.019 0.019 0.003 0.003 0.000 0.000 0.039 0.039 -0.042 -0.042 -0.017 -0.017 0.017 0.021\nMAP 0.492 0.575 0.474 0.578 0.610 0.694 0.386 0.463 - - 0.467 0.544 0.427 0.519 0.634 0.705 0.399 0.479 - -", "metadata": {"id": "6d79d8b8233699a74f132052f4d77442ffb5493d", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "MRR 0.503 0.577 0.486 0.553 0.629 0.695 0.592 0.611 - - 0.466 0.537 0.424 0.495 0.639 0.698 0.481 0.504 - -\neRAG NDCG 0.505 0.590 0.486 0.592 0.612 0.697 0.404 0.484 - - 0.481 0.560 0.440 0.536 0.635 0.705 0.403 0.484 - -\nAnnotations Pa 0.529 0.598 0.484 0.577 0.594 0.663 0.329 0.391 0.504 0.669 0.522 0.586 0.482 0.571 0.633 0.695 0.378 0.449 0.540 0.712\nR 0.519 0.519 0.426 0.426 0.619 0.619 0.301 0.301 - - 0.488 0.488 0.408 0.408 0.631 0.631 0.299 0.299 - -\nHitRatiob 0.519 0.519 0.426 0.426 0.619 0.619 0.301 0.301 0.390 0.532 0.488 0.488 0.408 0.408 0.631 0.631 0.299 0.299 0.414 0.561", "metadata": {"id": "14f49975ea00f3382992aad90877715aa33c84a7", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "aFornon-integerrelevancelabels,precisionisequaltoaverageoftherelevancelabels.\nbFornon-integerrelevancelabels,hitratioisequaltomaximumoftherelevancelabels.\n3.2 MainFindings\nHowdodifferentretrievalevaluationmethodscorrelatewith\ntheend-to-enddownstreamperformanceinRAG?. Tocom-\nparethedifferentevaluationstrategiesforevaluatingretrieverin\nRAG,wereportthecorrelationbetweenthescoresgeneratedfor\neachmethodandthedownstreamperformanceoftheLLM(i.e.,\nT5-smallwithFiDand50retrieveddocuments)inTable1.The\nresultsindicatethateRAGattainsthehighestcorrelationcompared", "metadata": {"id": "de132b3453b649cf1d2b13a5c29f1e6c2ca1dd43", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "resultsindicatethateRAGattainsthehighestcorrelationcompared\nFigure 1: The correlation between evaluation approaches\ntootherevaluationapproaches.Furthermore,theresultsshowthat\nandtheLLM’sdownstreamperformancevaryingnumber\nregardlessoftheretrievalmodelemployed,eRAGconsistentlyout-\nofretrieveddocumentsbyBM25.T5-smallwithFiDisused.\nperformsothersintermsofcorrelationwiththeLLM’sdownstream\nThemetricwiththehighestcorrelationinTable1isused.\nperformance.Interestingly,themostcommonapproaches,KILT", "metadata": {"id": "d9420a75a115e414eec0d08b8c88d474633e17d1", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "performance.Interestingly,themostcommonapproaches,KILT\nProvenanceandAnnotationwithLLMs,thatare,document-level oursuggestedevaluationstrategyconsistentlyexhibitsahigher\nrelevancelabelsandusingLLMstoassignarelevancelabeltoeach correlationwiththedownstreamperformanceoftheLLM.Further-\nretrieveddocument,havethelowestcorrelationwiththedown- more,theresultsillustratethataugmentingthenumberofretrieved\nstreamperformanceoftheLLM.Thisfindingconfirmsthatthe documentsleadstoadeclineincorrelation—aintuitiveobservation,", "metadata": {"id": "5e48e483201c4fc83a55a11b059a9528ce49b35c", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "LLMastheconsumeroftheretrievedresultsinRAGisthebest asallmetricsassesseachdocument-relevancelabelindependently\njudgefortheperformanceoftheretrievalmodel. forscoringarankedlist,whiletheLLMusesinformationfromthe\nentiretyofthesedocumentstoaccomplishitstask.\nHowdodifferentretrievalevaluationmethodsinRAGper- HowdoesourmethodcorrelatewiththedownstreamRAG\nformasthesizeofretrievalresultsincreases? Toaddressthis, performanceasthesizeoflargelanguagemodelsincreases?\nwevariedthenumberofretrieveddocumentsandcomputedthe Inaddressingthisquestion,wecomputedthecorrelationbetween", "metadata": {"id": "bffa24c0e7f2224e8668929eb08462ff3733fa3a", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "correlationbetweenthemetricwithhighestcorrelationforeach ourretrievalevaluationstrategyandthedownstreamperformance\nmethodinTable1ateachspecifiednumberofretrieveddocuments oftheLMswithtwodistinctsizes(i.e.,T5-smallwithFiDconsisting\nandthedownstreamperformanceoftheLLMgiventhatnumber of60MandT5-basewithFiDconsistingof220Mparameters).For\nofretrieveddocuments.Forthesakeofspace,welimitourexper- thesakeofspace,welimitourexperimentstothreedatasets:NQ\nimentstothreedatasets:NQforquestionanswering,FEVERfor forquestionanswering,FEVERforfact-checking,andWoWfor", "metadata": {"id": "58dc2a93c30ad5b71d3a3a320546e0cfe949d9b5", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "fact-checking,andWoWforlong-textgeneration.Theresultsof long-textgeneration.TheresultsillustratedinFigure2indicatethat,\nthisexperimentareshowninFigure1.Theoutcomesofthisexperi- forcertaindatasets,thereisahighercorrelationwiththesmaller\nmentrevealthatirrespectiveofthequantityofretrieveddocuments, LLM,whileforothers,ahighercorrelationisobservedwiththe\n2397", "metadata": {"id": "476d0e8ce3e9d0d06ea8f0611c14ae6227abc51b", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 3, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "SIGIR’24,July14–18,2024,Washington,DC,USA AlirezaSalemiandHamedZamani\nTable2:TheruntimeandmemoryconsumptionofeRAGin\ncomparisonwithend-to-endevaluation.T5-smallwithFiD,\nconsuming50documentsisused.\nRuntime(GPU) MemoryConsumption(GPU)\nDataset\nE2E eRAG E2E eRAG-Query eRAG-Document\nNQ 918sec 351sec 75.0GB 4.9GB 1.5GB\nTriviaQA 1819sec 686sec 46.2GB 5.4GB 1.5GB\nHotpotQA 1844sec 712sec 52.4GB 5.5GB 1.5GB\nFEVER 3395sec 1044sec 66.5GB 4.1GB 1.5GB\nFigure2:ThecorrelationbetweeneRAGandthedownstream WoW 912sec 740sec 47.9GB 6.5GB 1.5GB\nperformanceofdifferentLLMsizes.Inthisexperiment,T5-", "metadata": {"id": "28b9698da8b349b71c1f3dfa4f7808696334e777", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "performanceofdifferentLLMsizes.Inthisexperiment,T5-\nsmall(60Mparameters)andT5-base(220Mparameters)with\nFiDareused.ThedocumentsareretrievedusingBM25. utilizationoftheentireGPUmemory.Theresultsofthisexperiment\narereportedinTable2.Thefindingsindicatethat,onaverage,eRAG\nis2.468timesfasterthanend-to-endevaluation.Furtherelaborating,\nthespeedupforeRAGrangesfrom1.232to3.252timescomparedto\nend-to-endevaluationacrossthedatasets,wheretheleastspeedup\nisforthelong-textgenerationtask(i.e.,WoW).\nTocomparememoryconsumptionbetweeneRAGandend-to-\nendevaluation,weconductedtwoexperiments.First,wecompared", "metadata": {"id": "7ab05f142281b1c4024b60a33a0d78398dfa4ea3", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "endevaluation,weconductedtwoexperiments.First,wecompared\nthemaximummemoryrequiredbyend-to-endevaluationtoassess\nFigure3:ThecorrelationbetweeneRAGandthedownstream aquerywiththemaximummemorydemandedbyeRAGforthe\nperformanceofFiDandIPALLMs.T5-smallwith10docu- sameevaluation.Tocarryoutthiscomparison,weconfiguredthe\nmentsretrievedbyBM25isused.Thenumberofdocuments batchsizeforend-to-endevaluationto1,whileforeRAG,weset\nischosenbasedonthelimitationsoftheinputsizeinIPA. ittothesamenumberofdocumentsusedforonequerybyend-\nto-endevaluation(wecallthisquery-levelconfiguration).Inthe", "metadata": {"id": "8d63af7083ac54e3a73b3af5842d40aa6346081f", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "to-endevaluation(wecallthisquery-levelconfiguration).Inthe\nlargermodel.Nonetheless,innoneofthecasesisthereasignificant subsequentexperiments,wesetbothbatchsizesto1toassessthe\ndifferencebetweenthecorrelations,suggestingthattheproposed extenttowhicheRAGdemonstratessuperiormemoryefficiency\napproachiseffectiveregardlessoftheLLMsize. comparedtoend-to-endevaluationunderthemostefficientcon-\nfiguration(wecallthisdocument-levelconfiguration).Theresults\nHowdoesdifferentretrieval-augmentationapproachesaf-\noftheseexperimentsarereportedinTable2.Thefindingsindi-", "metadata": {"id": "6d0160580657209242f6a87cdd0b7a10812b3cbe", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "oftheseexperimentsarereportedinTable2.Thefindingsindi-\nfectthecorrelationbetweeneRAGandthedownstreamRAG\ncatethatinthequery-levelconfiguration,eRAGexhibitsbetween\nperformance? WeappliedeRAGtotwoLLMs.OneLLMutilizes\n7to15timesgreatermemoryefficiencycomparedtoend-to-end\nIn-PromptAugmentation(IPA),wheretheretrievedresultsareap-\nevaluation.Furthermore,inthedocument-levelconfiguration,this\npendedtotheinputoftheLLM.TheotherLLMemploysFusion-in-\nefficiencygapwidens,witheRAGdemonstrating30to48times\nDecoder(FiD)[9],whereineachretrieveddocumentisindividually", "metadata": {"id": "4377c226358ee2df7bb4e14aa3cb4e11b237e231", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Decoder(FiD)[9],whereineachretrieveddocumentisindividually\nmorememoryefficiencythanend-to-endevaluationacrossdiffer-\nprocessedbytheencoder,andsubsequently,therepresentations\nentdataset.Insummary,theseexperimentssuggestthateRAGis\nforalldocumentsareconcatenatedtogetherandfedtothedecoder.\nmoreefficientthanend-to-endevaluationofavanillatransformer,\nForthesakeofspace,welimitourexperimentstoNQforquestion\nexcellinginbothinferencetimeandmemoryutilization.\nanswering,FEVERforfact-checking,andWoWforlong-textgen-\neration.ThecorrelationbetweeneRAGandtheoutputsofeach\n4 CONCLUSION", "metadata": {"id": "d6d0547da1a6ddc1e8db70eda408d73bc7c4abbd", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "eration.ThecorrelationbetweeneRAGandtheoutputsofeach\n4 CONCLUSION\nLLMisillustratedinFigure3.Interestingly,theresultssuggestthat\nalthoughthereisnosignificantdifferencebetweenthecorrelation Thispaperexploresvariousapproachesforevaluatingretrieval\nof eRAGwith IPA and FiD LLMs, eRAG consistently exhibits a modelswithinaRAGpipeline.Additionally,itintroduceseRAG,a\nhighercorrelationwiththeFiD.Thisobservationcanbeelucidated novelapproachforevaluatingretrievalmodelsintheRAGpipeline.\nbyconsideringthedistinctionbetweenIPAandFiDmethodologies. eRAGleveragestheper-documentperformanceoftheLLMonthe", "metadata": {"id": "d3b429e3b2c478da07ae615e7d582ae08e1b7d62", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "InIPA,alldocumentsareconcatenatedtogetherandthenpresented downstreamtasktogeneraterelevancelabels.Thefindingssuggest\nasasingleinputtotheLLM.Incontrast,FiDprocesseseachdocu- thattheproposedapproachexhibitssignificantlyhighercorrelation\nmentindividuallybyfeedingthemseparatelytotheLLM’sencoder. withthedownstreamperformanceoftheLLM.Furthermore,eRAG\nGiventhatourapproachalignsmorecloselywithFiD,webelieve demonstratesgreaterefficiencythanend-to-endevaluationinterms\nthisalignmentisacontributingfactortothehighercorrelation ofbothmemoryconsumptionandinferencetime.", "metadata": {"id": "692d9a022fa5b832f57e8bcb2fde3b2781aa2507", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "thisalignmentisacontributingfactortothehighercorrelation ofbothmemoryconsumptionandinferencetime.\nbetweeneRAGandthedownstreamperformanceofFiD.\nACKNOWLEDGMENT\nHowmuchmoreefficientiseRAGcomparedtotheend-to-\nendevaluation? Here,weconsidertwofactors:inferencetime ThisworkwassupportedinpartbytheCenterforIntelligentIn-\nandmemoryconsumption.Forinferencetime,wecomparethetotal formationRetrieval,inpartbyLowe’s,andinpartbyanAmazon\ntimerequiredforend-to-endevaluationtogeneratescoreswiththe ResearchAward,Fall2022CFP.Anyopinions,findingsandconclu-", "metadata": {"id": "1174bad06bb9f7862024f9d18a310e68294b5bf3", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "totaltimeusedbyeRAG.Inthisexperiment,weoptforthebatch sionsorrecommendationsexpressedinthismaterialarethoseof\nsizeofeachapproachtobeaslargeaspossible,maximizingthe theauthorsanddonotnecessarilyreflectthoseofthesponsor.\n2398", "metadata": {"id": "898d6cc1681694da785b892b0b746d638d4269b4", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 4, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "EvaluatingRetrievalQualityinRetrieval-AugmentedGeneration SIGIR’24,July14–18,2024,Washington,DC,USA\nREFERENCES\n[18] JimmyLin,XueguangMa,Sheng-ChiehLin,Jheng-HongYang,RonakPradeep,\n[1] Garima Agrawal, Tharindu Kumarage, Zeyad Alghami, and Huan Liu. andRodrigoNogueira.2021. Pyserini:APythonToolkitforReproducibleIn-\n2023. CanKnowledgeGraphsReduceHallucinationsinLLMs?:ASurvey. formationRetrievalResearchwithSparseandDenseRepresentations.InPro-\narXiv:2311.07914[cs.CL] ceedingsofthe44thInternationalACMSIGIRConferenceonResearchandDe-", "metadata": {"id": "f872ce3b019cc80700d5ed5ed80b7e6fa7e9c820", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "arXiv:2311.07914[cs.CL] ceedingsofthe44thInternationalACMSIGIRConferenceonResearchandDe-\n[2] NickCraswell.2009.MeanReciprocalRank.SpringerUS,Boston,MA,1703–1703. velopmentinInformationRetrieval(VirtualEvent,Canada)(SIGIR’21).Asso-\nhttps://doi.org/10.1007/978-0-387-39940-9_488 ciationforComputingMachinery,NewYork,NY,USA,2356–2362. https:\n[3] RomainDeffayet,PhilippHager,Jean-MichelRenders,andMaartendeRijke.2023. //doi.org/10.1145/3404835.3463238\nAnOfflineMetricfortheDebiasednessofClickModels.InProceedingsofthe46th [19] IlyaLoshchilovandFrankHutter.2019.DecoupledWeightDecayRegularization.", "metadata": {"id": "7645eb691309fe0a6061af02c2fbb598fb888e48", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "InternationalACMSIGIRConferenceonResearchandDevelopmentinInformation InInternationalConferenceonLearningRepresentations. https://openreview.net/\nRetrieval(,Taipei,Taiwan,)(SIGIR’23).AssociationforComputingMachinery, forum?id=Bkg6RiCqY7\nNewYork,NY,USA,558–568. https://doi.org/10.1145/3539618.3591639 [20] FabioPetroni,AleksandraPiktus,AngelaFan,PatrickLewis,MajidYazdani,\n[4] EmilyDinan,StephenRoller,KurtShuster,AngelaFan,MichaelAuli,andJason NicolaDeCao,JamesThorne,YacineJernite,VladimirKarpukhin,JeanMail-", "metadata": {"id": "04904aa6424ca3a8f09f7d99786cc42d16e5418f", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Weston.2019.WizardofWikipedia:Knowledge-PoweredConversationalAgents. lard,VassilisPlachouras,TimRocktäschel,andSebastianRiedel.2021.KILT:a\nInInternationalConferenceonLearningRepresentations. https://openreview.net/ BenchmarkforKnowledgeIntensiveLanguageTasks.InProceedingsofthe2021\nforum?id=r1l73iRqKm ConferenceoftheNorthAmericanChapteroftheAssociationforComputational\n[5] MatthijsDouze,AlexandrGuzhva,ChengqiDeng,JeffJohnson,GergelySzilvasy, Linguistics:HumanLanguageTechnologies,KristinaToutanova,AnnaRumshisky,", "metadata": {"id": "20e451d364c4540432fea5e6a9fa9cf83d045a32", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Pierre-EmmanuelMazaré,MariaLomeli,LucasHosseini,andHervéJégou.2024. LukeZettlemoyer,DilekHakkani-Tur,IzBeltagy,StevenBethard,RyanCotterell,\nTheFaisslibrary.(2024).arXiv:2401.08281[cs.LG] TanmoyChakraborty,andYichaoZhou(Eds.).AssociationforComputational\n[6] FanGuo,ChaoLiu,andYiMinWang.2009. Efficientmultiple-clickmodels Linguistics,Online,2523–2544. https://doi.org/10.18653/v1/2021.naacl-main.200\ninwebsearch.InProceedingsoftheSecondACMInternationalConferenceon [21] ColinRaffel,NoamShazeer,AdamRoberts,KatherineLee,SharanNarang,", "metadata": {"id": "5f5aceac65cdb14d4f554872bd8f0330f6f59a57", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "WebSearchandDataMining(Barcelona,Spain)(WSDM’09).Associationfor MichaelMatena,YanqiZhou,WeiLi,andPeterJ.Liu.2020. Exploringthe\nComputingMachinery,NewYork,NY,USA,124–131. https://doi.org/10.1145/ limitsoftransferlearningwithaunifiedtext-to-texttransformer.J.Mach.Learn.\n1498759.1498818 Res.21,1,Article140(jan2020),67pages.\n[7] GautierIzacard,MathildeCaron,LucasHosseini,SebastianRiedel,PiotrBo- [22] StephenE.Robertson,SteveWalker,SusanJones,MichelineHancock-Beaulieu,", "metadata": {"id": "dde9874bd97d0bacc19f5d85ba378f2ab3a08308", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "janowski,ArmandJoulin,andEdouardGrave.2022.UnsupervisedDenseInfor- andMikeGatford.1994.OkapiatTREC-3.InTextRetrievalConference. https:\nmationRetrievalwithContrastiveLearning.TransactionsonMachineLearning //api.semanticscholar.org/CorpusID:3946054\nResearch(2022). https://openreview.net/forum?id=jKN1pXi7b0 [23] JonSaad-Falcon,OmarKhattab,ChristopherPotts,andMateiZaharia.2023.\n[8] GautierIzacardandEdouardGrave.2021. DistillingKnowledgefromReader ARES:AnAutomatedEvaluationFrameworkforRetrieval-AugmentedGenera-", "metadata": {"id": "3e3ec111bac5a5802d989ada5dad4212b3399f17", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "toRetrieverforQuestionAnswering.InInternationalConferenceonLearning tionSystems. arXiv:2311.09476[cs.CL]\nRepresentations. https://openreview.net/forum?id=NTEz-6wysdb [24] AlirezaSalemi,JuanAltmayerPizzorno,andHamedZamani.2023.ASymmet-\n[9] GautierIzacardandEdouardGrave.2021. LeveragingPassageRetrievalwith ricDualEncodingDenseRetrievalFrameworkforKnowledge-IntensiveVisual\nGenerativeModelsforOpenDomainQuestionAnswering.InProceedingsofthe QuestionAnswering.InProceedingsofthe46thInternationalACMSIGIRCon-", "metadata": {"id": "5e601620e94382547e8fb96922459cf4afca1be0", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "16thConferenceoftheEuropeanChapteroftheAssociationforComputational ferenceonResearchandDevelopmentinInformationRetrieval(Taipei,Taiwan)\nLinguistics:MainVolume,PaolaMerlo,JorgTiedemann,andReutTsarfaty(Eds.). (SIGIR’23).AssociationforComputingMachinery,NewYork,NY,USA,110–120.\nAssociationforComputationalLinguistics,Online,874–880. https://doi.org/10. https://doi.org/10.1145/3539618.3591629\n18653/v1/2021.eacl-main.74 [25] AlirezaSalemi,SuryaKallumadi,andHamedZamani.2024.OptimizationMeth-", "metadata": {"id": "4d49d7a9e655e37fdf0ba5306502c4e58d3fca8c", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "18653/v1/2021.eacl-main.74 [25] AlirezaSalemi,SuryaKallumadi,andHamedZamani.2024.OptimizationMeth-\n[10] JithinJamesandShahulEs.2023.Ragas:Evaluationframeworkforyourretrieval odsforPersonalizingLargeLanguageModelsthroughRetrievalAugmentation.\naugmentedgeneration(rag)pipelines.https://github.com/explodinggradients/ InProceedingsofthe47thAnnualInternationalACMSIGIRConferenceonResearch\nragas. andDevelopmentinInformationRetrieval(Washington,DC,USA)(SIGIR’24). (to\n[11] KalervoJärvelinandJaanaKekäläinen.2000.IRevaluationmethodsforretrieving appear).", "metadata": {"id": "d6e515c694c60b440028b2dd3af7f7fcb377527a", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "[11] KalervoJärvelinandJaanaKekäläinen.2000.IRevaluationmethodsforretrieving appear).\nhighlyrelevantdocuments.InProceedingsofthe23rdAnnualInternationalACM [26] Alireza Salemi, Sheshera Mysore, Michael Bendersky, and Hamed Za-\nSIGIRConferenceonResearchandDevelopmentinInformationRetrieval(Athens, mani. 2023. LaMP: When Large Language Models Meet Personalization.\nGreece)(SIGIR’00).AssociationforComputingMachinery,NewYork,NY,USA, arXiv:2304.11406[cs.CL]\n41–48. https://doi.org/10.1145/345508.345545 [27] AlirezaSalemi,MahtaRafiee,andHamedZamani.2023. Pre-TrainingMulti-", "metadata": {"id": "87accfa0ec483c695385d5fc8f21d16d076424a8", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "[12] AlbertQ.Jiang,AlexandreSablayrolles,ArthurMensch,ChrisBamford,De- ModalDenseRetrieversforOutside-KnowledgeVisualQuestionAnswering.In\nvendraSinghChaplot,DiegodelasCasas,FlorianBressand,GiannaLengyel, Proceedingsofthe2023ACMSIGIRInternationalConferenceonTheoryofInforma-\nGuillaumeLample,LucileSaulnier,LélioRenardLavaud,Marie-AnneLachaux, tionRetrieval(Taipei,Taiwan)(ICTIR’23).AssociationforComputingMachinery,\nPierreStock,TevenLeScao,ThibautLavril,ThomasWang,TimothéeLacroix, NewYork,NY,USA,169–176. https://doi.org/10.1145/3578337.3605137", "metadata": {"id": "8f30e22f980d0c023cd79a422ae26d85fc63ec65", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "andWilliamElSayed.2023.Mistral7B. arXiv:2310.06825[cs.CL] [28] DoniaScott,RossanoBarone,andRobKoeling.2012.CorpusAnnotationasa\n[13] MandarJoshi,EunsolChoi,DanielWeld,andLukeZettlemoyer.2017.TriviaQA:A ScientificTask.InProceedingsoftheEighthInternationalConferenceonLanguage\nLargeScaleDistantlySupervisedChallengeDatasetforReadingComprehension. ResourcesandEvaluation(LREC’12),NicolettaCalzolari,KhalidChoukri,Thierry\nInProceedingsofthe55thAnnualMeetingoftheAssociationforComputational Declerck,MehmetUğurDoğan,BenteMaegaard,JosephMariani,Asuncion", "metadata": {"id": "914aabf057eab638ee000a970b8227fe7c7db474", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Linguistics(Volume1:LongPapers),ReginaBarzilayandMin-YenKan(Eds.). Moreno,JanOdijk,andSteliosPiperidis(Eds.).EuropeanLanguageResources\nAssociationforComputationalLinguistics,Vancouver,Canada,1601–1611. https: Association(ELRA),Istanbul,Turkey,1481–1485. http://www.lrec-conf.org/\n//doi.org/10.18653/v1/P17-1147 proceedings/lrec2012/pdf/569_Paper.pdf\n[14] VladimirKarpukhin,BarlasOguz,SewonMin,PatrickLewis,LedellWu,Sergey [29] KurtShuster,SpencerPoff,MoyaChen,DouweKiela,andJasonWeston.2021.", "metadata": {"id": "048990350b1e73bb4750c3f21b4961e7a7ea6999", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Edunov,DanqiChen,andWen-tauYih.2020.DensePassageRetrievalforOpen- RetrievalAugmentationReducesHallucinationinConversation.InFindings\nDomainQuestionAnswering.InProceedingsofthe2020ConferenceonEmpirical oftheAssociationforComputationalLinguistics:EMNLP2021.Associationfor\nMethodsinNaturalLanguageProcessing(EMNLP),BonnieWebber,TrevorCohn, ComputationalLinguistics,PuntaCana,DominicanRepublic,3784–3803. https:\nYulanHe,andYangLiu(Eds.).AssociationforComputationalLinguistics,Online, //doi.org/10.18653/v1/2021.findings-emnlp.320", "metadata": {"id": "0941a5be7aabacc176b1c706fd8186fbb012b758", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "6769–6781. https://doi.org/10.18653/v1/2020.emnlp-main.550 [30] Paul Thomas, Seth Spielman, Nick Craswell, and Bhaskar Mitra. 2023.\n[15] TomKwiatkowski,JennimariaPalomaki,OliviaRedfield,MichaelCollins,Ankur Large language models can accurately predict searcher preferences.\nParikh,ChrisAlberti,DanielleEpstein,IlliaPolosukhin,JacobDevlin,KentonLee, arXiv:2309.10621[cs.IR]\nKristinaToutanova,LlionJones,MatthewKelcey,Ming-WeiChang,AndrewM. [31] JamesThorne,AndreasVlachos,ChristosChristodoulopoulos,andArpitMittal.", "metadata": {"id": "b55576303233c08d27423fd2434ba73dab5d26ca", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Dai,JakobUszkoreit,QuocLe,andSlavPetrov.2019. NaturalQuestions:A 2018. FEVER:aLarge-scaleDatasetforFactExtractionandVERification.In\nBenchmarkforQuestionAnsweringResearch.TransactionsoftheAssociationfor Proceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociation\nComputationalLinguistics7(2019),452–466. https://doi.org/10.1162/tacl_a_00276 forComputationalLinguistics:HumanLanguageTechnologies,Volume1(Long\n[16] PatrickLewis,EthanPerez,AleksandraPiktus,FabioPetroni,VladimirKarpukhin, Papers),MarilynWalker,HengJi,andAmandaStent(Eds.).Associationfor", "metadata": {"id": "9aeedb878a77b2bb04b5016f3c6c26d83297e28e", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "NamanGoyal,HeinrichKüttler,MikeLewis,Wen-tauYih,TimRocktäschel, ComputationalLinguistics,NewOrleans,Louisiana,809–819. https://doi.org/10.\nSebastianRiedel,andDouweKiela.2020.Retrieval-augmentedgenerationfor 18653/v1/N18-1074\nknowledge-intensiveNLPtasks.InProceedingsofthe34thInternationalConference [32] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,\nonNeuralInformationProcessingSystems(Vancouver,BC,Canada)(NIPS’20). AidanNGomez,ŁukaszKaiser,andIlliaPolosukhin.2017. AttentionisAll", "metadata": {"id": "c22b00e1d5728d054a89739d0c5b3d6a2453c3b2", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "CurranAssociatesInc.,RedHook,NY,USA,Article793,16pages. youNeed.InAdvancesinNeuralInformationProcessingSystems,I.Guyon,U.Von\n[17] Chin-YewLin.2004.ROUGE:APackageforAutomaticEvaluationofSummaries. Luxburg,S.Bengio,H.Wallach,R.Fergus,S.Vishwanathan,andR.Garnett(Eds.),\nInTextSummarizationBranchesOut.AssociationforComputationalLinguistics, Vol.30.CurranAssociates,Inc. https://proceedings.neurips.cc/paper_files/paper/\nBarcelona,Spain,74–81. https://aclanthology.org/W04-1013 2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n[33] ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,WilliamCohen,Ruslan", "metadata": {"id": "172658fd496c281ec0549d34bff42c4e9f335277", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "[33] ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,WilliamCohen,Ruslan\nSalakhutdinov,andChristopherD.Manning.2018. HotpotQA:ADatasetfor\nDiverse,ExplainableMulti-hopQuestionAnswering.InProceedingsofthe2018\nConferenceonEmpiricalMethodsinNaturalLanguageProcessing,EllenRiloff,\n2399", "metadata": {"id": "f0929ed9c2ecf5f72dcdafae5432cf9797203b9d", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 5, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "SIGIR’24,July14–18,2024,Washington,DC,USA AlirezaSalemiandHamedZamani\nDavidChiang,JuliaHockenmaier,andJun’ichiTsujii(Eds.).Associationfor andDevelopmentinInformationRetrieval(SIGIR’24). (toappear).\nComputationalLinguistics,Brussels,Belgium,2369–2380. https://doi.org/10. [35] HamedZamani,FernandoDiaz,MostafaDehghani,DonaldMetzler,andMichael\n18653/v1/D18-1259 Bendersky.2022.Retrieval-EnhancedMachineLearning.InProceedingsofthe45th\n[34] HamedZamaniandMichaelBendersky.2024. StochasticRAG:End-to-End InternationalACMSIGIRConferenceonResearchandDevelopmentinInformation", "metadata": {"id": "57a4edb8ea8bf2c7e32cfb928cafef670d3bd7f2", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 6, "created_at": "2025-09-07T19:33:09Z"}}
{"content": "Retrieval-AugmentedGenerationthroughExpectedUtilityMaximization.In Retrieval(Madrid,Spain)(SIGIR’22).AssociationforComputingMachinery,New\nProceedingsofthe47thAnnualInternationalACMSIGIRConferenceonResearch York,NY,USA,2875–2886. https://doi.org/10.1145/3477495.3531722\n2400", "metadata": {"id": "a1d8a09b399b1657714206cfef151102f90e86f2", "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation.pdf", "page": 6, "created_at": "2025-09-07T19:33:09Z"}}
